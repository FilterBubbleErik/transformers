{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b220be2a-9a82-4f7e-8b32-df6296c5f038",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9b504-dfb2-46b2-823c-25b3b7ae4046",
   "metadata": {},
   "source": [
    "## 1. Transformers\n",
    "\n",
    "Testing the usage instructions from https://huggingface.co/transformers/task_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c90588-bcfb-465a-8cbc-42dfcee88a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = classifier(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6649c3-f004-4657-ba4b-6d733bfc5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipe = pipeline(\"ner\")\n",
    "\n",
    "sequence = \"\"\"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO,\n",
    "therefore very close to the Manhattan Bridge which is visible from the window.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8193e18-a121-4f10-a15e-a488356b1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_pipe(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840e14e-c8af-4a31-8377-54481f585ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model(inputs)[0]\n",
    "predictions = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0618ed6-e1b1-4c3c-8a01-ea4063eba729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e396a-b910-4857-80f3-c2e8de553276",
   "metadata": {},
   "source": [
    "## 2. BERT\n",
    "\n",
    "Testing instructions from https://huggingface.co/transformers/model_doc/bert.html\n",
    "\n",
    "There are two groups of BERT modules. The standard one (BERT) uses PyTorch but we need the transformers version (TFBERT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18d4b4-9466-44c4-8d1e-04f5470bb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForTokenClassification.from_pretrained('bert-base-cased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "inputs[\"labels\"] = tf.reshape(tf.constant([1] * tf.size(input_ids).numpy()), (-1, tf.size(input_ids))) # Batch size 1\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c84b1-5258-4cb5-be96-5c5b2b5ded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df626404-0761-4b2d-8941-f272a279251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb7668-2c2a-4395-a07d-d35a490a6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5f407-3daf-40f5-8f47-379a58dbab7d",
   "metadata": {},
   "source": [
    "## 3. BERTje\n",
    "\n",
    "Instructions: https://huggingface.co/GroNLP/bert-base-dutch-cased\n",
    "\n",
    "Alternative models used by Bouma 2021: RobBERT (Delobelle), mBERT (Google), XLM-R (Conneau)\n",
    "\n",
    "BERTje paper also mentions BERT-NL (textdata.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa219b-2274-427b-b53f-f624706b8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26add8ac-f610-46f7-a089-bf2c34faa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"Dit is een test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d76a34-454d-4a26-98e1-c00ac6145ec4",
   "metadata": {},
   "source": [
    "These instructions could be useful: \n",
    "* https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "* https://www.tensorflow.org/official_models/fine_tuning_bert\n",
    "\n",
    "Even more: https://duckduckgo.com/?q=bert+tensorflow+text+classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b68c81-e383-4abb-8adf-9b10bf3d3302",
   "metadata": {},
   "source": [
    "### 3.1 IMDB data set\n",
    "\n",
    "Instructions: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879579d-9af2-4276-8088-b2f9c54f882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daf64f-7eaf-456c-9f07-26c1f3adb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e567d-7a9b-41f3-865e-3d61054ae9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa8b92-2f57-4241-8a03-9c8b8ba35bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c504a-bdd3-4d32-b9ff-d1d263450421",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983aeaf-43c3-4112-8964-578313925629",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd1b5-a102-4cfb-8790-f3a2fc2ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbeaf59-b83a-405c-b154-ff6b283bda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58664363-62e0-4072-a8f2-ef014967f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd5c5f-28a1-45f4-918e-35d4f4234b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beca42-f4b1-4453-9182-f43a18a6329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82479d1a-52ca-4086-ac01-2c36b214fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c310bc-f1f1-415c-993f-94eff5b2f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafad7d-02fd-40e7-b31a-657a876df640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3d33f-9574-4388-8240-31b6995c154b",
   "metadata": {},
   "source": [
    "FATAL ERROR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208a22a-a102-48d3-85ef-53144f00a57b",
   "metadata": {},
   "source": [
    "### 3.2 Sentiment analysis\n",
    "\n",
    "Instructions: https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e139293-9444-4dab-967d-ad9c31e85b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8845cb-31e2-4ff2-92cb-0735c81b9423",
   "metadata": {},
   "source": [
    "Load IMDB data (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e60592-3186-4352-8bfa-503d8ba85abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f51250-79d1-4bca-9590-f3ddc7923992",
   "metadata": {},
   "source": [
    "Load social distancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2365461c-88de-4b04-b6fd-4e39c9732367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5977 files belonging to 2 classes.\n",
      "Using 4782 files for training.\n",
      "Found 5977 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 11:43:31.667176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-20 11:43:31.667199: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-20 11:43:31.667215: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (eslt0070): /proc/driver/nvidia/version does not exist\n",
      "2021-07-20 11:43:31.667840: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1195 files for validation.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "DATA_DIR = 'social_distancing_relevance'\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7525a2c4-cffb-45b9-a26f-bc39570283f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'RT @renevanm: Niet knuffelen, geen seks, 2 meter afstand houden... ik zit blijkbaar al geruime tijd in quarantaine.\\n'\n",
      "Label : 1 (RELEVANT)\n",
      "Review: b'@Witty966 Ze volgen de onderzoeken niet of willen het niet weten!\\\\n\\\\n1.5 meter afstand helpt niets wanneer niet wordt geventileerd!\\\\n\\\\nhttps://t.co/u8Ga2Kpuoy\\n'\n",
      "Label : 1 (RELEVANT)\n",
      "Review: b'@iOnAsJ @slecluyse @GeertNoels @Stijn_Baert ja inderdaad, gisteren dochter, echtgenoot, kleinkind thuis ontvangen, anderhalve meter? dat kon gewoonweg niet, meteen mondmasker aangedaan en ontsmettingsgel erbij genomen, maw...  zo was het niet gezellig. We gaan vrijwillig terug naar oude situatie. buiten aan de deur dus.\\n'\n",
      "Label : 1 (RELEVANT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 11:43:32.072613: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-20 11:43:32.073469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899885000 Hz\n",
      "2021-07-20 11:43:32.125209: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(f'Review: {text_batch.numpy()[i]}')\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12399680-406c-4f01-92b2-9a54bbd3a2ad",
   "metadata": {},
   "source": [
    "This is the place where the BERT model is selected. There are mainly English language models available with one multi-lingual model which crashes the machine. No working Dutch models are found at the related website.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14af5749-fe8b-4996-a616-97a18484fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'bert_multi_cased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/google/wiki40b-lm-nl/1',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7147730-1d50-45ef-bc74-b322ba74f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3, Total size: 2.69MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3'.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f9665ef-a704-4c5d-b75d-51a8b9849951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101 10531 10124 11049 10151 28149 19308 18379   106   102     0     0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0af5ad4-e759-43b2-b866-e3454d7aab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3'.\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 30.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 60.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 90.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 120.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 150.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 180.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 210.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 240.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 270.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 300.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 330.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 360.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 390.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 420.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 450.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 480.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 510.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 540.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 570.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 600.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 630.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 660.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3: 681.28MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3, Total size: 695.91MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3'.\n",
      "2021-07-20 11:52:10.368980: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 367248384 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2732f84-d2e9-4a71-b9d5-6ee745211cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[ 0.6052361  -0.03562833  0.34877217 -0.41043743 -0.39114502  0.52867943\n",
      "  0.4629631   0.08782487 -0.47338453  0.35345632 -0.06693023 -0.27646577]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[-0.33073407  0.14612621 -0.06266934 ...  0.84484535 -0.12296543\n",
      "   0.77432895]\n",
      " [-0.8536666  -0.01048076 -0.10002846 ...  0.4412018  -0.23505431\n",
      "   0.6783054 ]\n",
      " [-0.7773089   0.40002573 -0.17473161 ...  0.7971061  -0.21617687\n",
      "   0.8154314 ]\n",
      " ...\n",
      " [-0.53897893  0.20686042  0.33575624 ...  0.5694974  -0.24205497\n",
      "   0.53376555]\n",
      " [-0.5707657   0.10813653  0.18492147 ...  0.8677025  -0.16494572\n",
      "   0.56380117]\n",
      " [-0.56603634  0.1004438   0.17902762 ...  0.80625296 -0.11992311\n",
      "   0.53856736]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "866f7a7a-9796-4e93-bbda-dcd4cf8e4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5448bf7c-6049-4c0f-b180-4e7dac6ca4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 11:52:22.728585: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 367248384 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.8319441]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dca8b98c-2db1-461e-809d-b2c4cec1cbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6774fad7-2271-4d0c-b276-4b40421b14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56bc55ff-5d5a-4d78-82b8-0e6f662bf27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Adamw optimizer\n",
      "INFO:absl:gradient_clip_norm=1.000000\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05ca934f-2a7b-4820-a4bf-debceeb055d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf874-f5c9-4131-814d-8cda102906e2",
   "metadata": {},
   "source": [
    "This takes a lot of time (5 hours for imdb data), so skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ff96d-30a1-4862-849e-1e6a0d052b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n",
      "Epoch 1/5\n",
      " 77/150 [==============>...............] - ETA: 36:14 - loss: 0.5546 - binary_accuracy: 0.7277"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8c4e0-b82c-4f1d-84b9-a28f43deb1c6",
   "metadata": {},
   "source": [
    "Results for social distancing data on training data:\n",
    "\n",
    "| type | classes | 1 | 2 | 3 | 4 | 5 |\n",
    "| -- | -- | -- | -- | -- | -- | -- |\n",
    "| bert_en_uncased_L-12_H-768_A-12  | 3 | 0.550 | 0.565 | 0.580 | 0.580 | 0.587 |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 3 | 0.536 | 0.554 | 0.571 | 0.599 | 0.616  |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 2 | 0.791 | 0.797 | 0.843 | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d5fef-e7f3-4ed0-a03a-312a59535c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ffe5e-e957-42a8-9f0c-baf52a6e1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c330f8-4d49-400a-8fca-f308c4e6b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c84ec-fa5b-4ebb-b10b-d3f844fcee1a",
   "metadata": {},
   "source": [
    "Resume processing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf72f10-3858-4e5b-baa8-37e2d8959a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ce021-b9ff-48f1-988b-7eacc93b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'iedereen moet afstand houden',  # this is the same sentence tried earlier\n",
    "    'hou afstand',\n",
    "    'niemand houdt afstand',\n",
    "    'de afstand tot het doel is 11 meter',\n",
    "    'ze moeten stoppen met maatregelen als 1,5 m'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "# original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "# print('Results from the model in memory:')\n",
    "# print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac233bd1-5a70-4394-8087-7e7b33bf8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_results = reloaded_model \\\n",
    "            .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679868d2-0655-4eb1-82e8-607bff08f3fc",
   "metadata": {},
   "source": [
    "### 3.3 Prepare data for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a374f-d02f-4f15-b497-f35f72302f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6eae7-634b-4ec1-bd9e-6b9199e3fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_IN = \"../../puregome/data/annotation/\"\n",
    "TEXT_FILE = os.path.join(DATA_DIR_IN, \"distance-tweets.csv\")\n",
    "LABEL_FILE = TEXT_FILE + \".human-labels.txt\"\n",
    "DATA_DIR_OUT = \"social_distancing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274ada5-9233-45ef-bd3d-6f207e04466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text_df, label_df):\n",
    "    data_dict = {}\n",
    "    target_annotator = \"\"\n",
    "    for i, row in label_df.iterrows():\n",
    "        if target_annotator == \"\":\n",
    "            target_annotator = row[\"annotator\"]\n",
    "        if row[\"id_str\"] in text_df.index and row[\"annotator\"] == target_annotator:\n",
    "            data_dict[row[\"id_str\"]] = { \"label\": row[\"label\"], \"text\": text_df.loc[row[\"id_str\"]][\"text\"] }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabe949-1e4d-4c6b-aa96-c79ead056771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(data_dict):\n",
    "    for id_str in data_dict:\n",
    "        out_dir = os.path.join(DATA_DIR_OUT, data_dict[id_str][\"label\"])\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        out_file = open(os.path.join(out_dir, str(id_str) + \".txt\"), \"w\")\n",
    "        print(data_dict[id_str][\"text\"], file=out_file)\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eab65e-0442-4284-8a77-1c1a7dffc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(TEXT_FILE, index_col=\"id_str\")\n",
    "label_df = pd.read_csv(LABEL_FILE, sep=\" \", header=None, names=[\"annotator\", \"date\", \"id_str\", \"data_set_id\", \"label\"])\n",
    "data_dict = extract_data(text_df, label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48f7c4-1ecc-4016-b839-d3e2ff5436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628f3ad-22f1-47ca-9dfb-9b037ac8fea1",
   "metadata": {},
   "source": [
    "This stores the tweets in subdirectories of `social_distancing` where the names of the subdirectories are equal to the labels and where each tweet is stored in a file named `id_str.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544ba4b-795a-4db0-9ad1-9805a32eeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62e246-6971-402b-b57d-b2b68ef656e2",
   "metadata": {},
   "source": [
    "## 4. ROBBERT\n",
    "\n",
    "Instructions: https://huggingface.co/pdelobelle/robbert-v2-dutch-base and https://github.com/iPieter/RobBERT\n",
    "\n",
    "Requires PyTorch: https://pytorch.org/<br>\n",
    "Installation command (select: pip & CPU): `pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ae6baa-9f2b-42e3-8066-3ef3c226b31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e173ee2a8574a54b93398ad0ba5e7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0ac772333340afa343f973e104fbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652d85cb-3f72-4cc6-aa2e-8b816a89aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d25db891504c55ae7551600e3a71cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfaf41f93794b3aaec6e3191a052c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26386e4263e64c58aaf8206c395fcd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c1bd526e80424dbba9bc352d6010c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaad43ec41d4526a2ee1cbf0b108822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1d4dce-56f6-449b-87d3-0007909cefc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1636, -0.0760]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d3f7ae-a94a-45cd-b90d-3d70078957fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 495, 405, 16, 364, 225, 1296, 328, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Dit is een test!\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf1c176a-311a-4e2f-b937-e2177d40518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Dit is een test!</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0, 495, 405, 16, 364, 225, 1296, 328, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00b91c11-c08b-4a34-95d6-547287eb584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"The capital of France is <mask>.\", return_tensors=\"pt\")\n",
    "labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd133dc-eb5d-484f-86ed-6219e59b9b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[34.8744, -3.8884, 18.9567,  ...,  2.8639,  5.2812, 11.2557],\n",
       "         [ 8.5224, -2.9420, 19.8858,  ...,  2.7513,  4.0812,  8.5191],\n",
       "         [-3.2755, -4.2489,  9.6843,  ..., -1.3403, -2.0838, -0.4035],\n",
       "         ...,\n",
       "         [-4.8167, -3.8881,  8.3117,  ..., -4.3991, -5.6916,  1.1575],\n",
       "         [20.6686, -4.4710, 20.3602,  ...,  0.9624,  3.1282,  7.1575],\n",
       "         [11.6269, -3.6408, 32.1565,  ...,  2.0802, -0.2959,  9.1577]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a8f2c-fe24-4ea6-b740-8869a29d99b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
