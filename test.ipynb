{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b220be2a-9a82-4f7e-8b32-df6296c5f038",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9b504-dfb2-46b2-823c-25b3b7ae4046",
   "metadata": {},
   "source": [
    "## 1. Transformers\n",
    "\n",
    "Testing the usage instructions from https://huggingface.co/transformers/task_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c90588-bcfb-465a-8cbc-42dfcee88a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = classifier(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6649c3-f004-4657-ba4b-6d733bfc5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipe = pipeline(\"ner\")\n",
    "\n",
    "sequence = \"\"\"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO,\n",
    "therefore very close to the Manhattan Bridge which is visible from the window.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8193e18-a121-4f10-a15e-a488356b1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_pipe(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840e14e-c8af-4a31-8377-54481f585ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model(inputs)[0]\n",
    "predictions = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0618ed6-e1b1-4c3c-8a01-ea4063eba729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e396a-b910-4857-80f3-c2e8de553276",
   "metadata": {},
   "source": [
    "## 2. BERT\n",
    "\n",
    "Testing instructions from https://huggingface.co/transformers/model_doc/bert.html\n",
    "\n",
    "There are two groups of BERT modules. The standard one (BERT) uses PyTorch but we need the transformers version (TFBERT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18d4b4-9466-44c4-8d1e-04f5470bb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForTokenClassification.from_pretrained('bert-base-cased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "inputs[\"labels\"] = tf.reshape(tf.constant([1] * tf.size(input_ids).numpy()), (-1, tf.size(input_ids))) # Batch size 1\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c84b1-5258-4cb5-be96-5c5b2b5ded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df626404-0761-4b2d-8941-f272a279251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb7668-2c2a-4395-a07d-d35a490a6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5f407-3daf-40f5-8f47-379a58dbab7d",
   "metadata": {},
   "source": [
    "## 3. BERTje\n",
    "\n",
    "Instructions: https://huggingface.co/GroNLP/bert-base-dutch-cased\n",
    "\n",
    "Alternative models used by Bouma 2021: RobBERT (Delobelle), mBERT (Google), XLM-R (Conneau)\n",
    "\n",
    "BERTje paper also mentions BERT-NL (textdata.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa219b-2274-427b-b53f-f624706b8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26add8ac-f610-46f7-a089-bf2c34faa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"Dit is een test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d76a34-454d-4a26-98e1-c00ac6145ec4",
   "metadata": {},
   "source": [
    "These instructions could be useful: \n",
    "* https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "* https://www.tensorflow.org/official_models/fine_tuning_bert\n",
    "\n",
    "Even more: https://duckduckgo.com/?q=bert+tensorflow+text+classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b68c81-e383-4abb-8adf-9b10bf3d3302",
   "metadata": {},
   "source": [
    "### 3.1 IMDB data set\n",
    "\n",
    "Instructions: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879579d-9af2-4276-8088-b2f9c54f882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daf64f-7eaf-456c-9f07-26c1f3adb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e567d-7a9b-41f3-865e-3d61054ae9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa8b92-2f57-4241-8a03-9c8b8ba35bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c504a-bdd3-4d32-b9ff-d1d263450421",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983aeaf-43c3-4112-8964-578313925629",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd1b5-a102-4cfb-8790-f3a2fc2ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbeaf59-b83a-405c-b154-ff6b283bda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58664363-62e0-4072-a8f2-ef014967f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd5c5f-28a1-45f4-918e-35d4f4234b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beca42-f4b1-4453-9182-f43a18a6329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82479d1a-52ca-4086-ac01-2c36b214fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c310bc-f1f1-415c-993f-94eff5b2f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafad7d-02fd-40e7-b31a-657a876df640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3d33f-9574-4388-8240-31b6995c154b",
   "metadata": {},
   "source": [
    "FATAL ERROR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208a22a-a102-48d3-85ef-53144f00a57b",
   "metadata": {},
   "source": [
    "### 3.2 Sentiment analysis\n",
    "\n",
    "Instructions: https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e139293-9444-4dab-967d-ad9c31e85b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 10:44:20.473304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-22 10:44:20.473339: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8845cb-31e2-4ff2-92cb-0735c81b9423",
   "metadata": {},
   "source": [
    "Load IMDB data (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e60592-3186-4352-8bfa-503d8ba85abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f51250-79d1-4bca-9590-f3ddc7923992",
   "metadata": {},
   "source": [
    "Load social distancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2365461c-88de-4b04-b6fd-4e39c9732367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5977 files belonging to 2 classes.\n",
      "Using 4782 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 10:44:27.435714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-22 10:44:27.435743: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-22 10:44:27.435774: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (eslt0070): /proc/driver/nvidia/version does not exist\n",
      "2021-07-22 10:44:27.436496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5977 files belonging to 2 classes.\n",
      "Using 1195 files for validation.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "DATA_DIR = 'social_distancing_relevance'\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7525a2c4-cffb-45b9-a26f-bc39570283f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'RT @renevanm: Niet knuffelen, geen seks, 2 meter afstand houden... ik zit blijkbaar al geruime tijd in quarantaine.\\n'\n",
      "Label : 1 (RELEVANT)\n",
      "Review: b'@Witty966 Ze volgen de onderzoeken niet of willen het niet weten!\\\\n\\\\n1.5 meter afstand helpt niets wanneer niet wordt geventileerd!\\\\n\\\\nhttps://t.co/u8Ga2Kpuoy\\n'\n",
      "Label : 1 (RELEVANT)\n",
      "Review: b'@iOnAsJ @slecluyse @GeertNoels @Stijn_Baert ja inderdaad, gisteren dochter, echtgenoot, kleinkind thuis ontvangen, anderhalve meter? dat kon gewoonweg niet, meteen mondmasker aangedaan en ontsmettingsgel erbij genomen, maw...  zo was het niet gezellig. We gaan vrijwillig terug naar oude situatie. buiten aan de deur dus.\\n'\n",
      "Label : 1 (RELEVANT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 10:44:28.764990: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-22 10:44:28.785081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899885000 Hz\n",
      "2021-07-22 10:44:28.826286: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(f'Review: {text_batch.numpy()[i]}')\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12399680-406c-4f01-92b2-9a54bbd3a2ad",
   "metadata": {},
   "source": [
    "This is the place where the BERT model is selected. There are mainly English language models available with one multi-lingual model which crashes the machine. No working Dutch models are found at the related website.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14af5749-fe8b-4996-a616-97a18484fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'bert_multi_cased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/google/wiki40b-lm-nl/1',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7147730-1d50-45ef-bc74-b322ba74f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9665ef-a704-4c5d-b75d-51a8b9849951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101 10531 10124 11049 10151 28149 19308 18379   106   102     0     0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0af5ad4-e759-43b2-b866-e3454d7aab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2732f84-d2e9-4a71-b9d5-6ee745211cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[ 0.6052361  -0.03562833  0.34877217 -0.41043743 -0.39114502  0.52867943\n",
      "  0.4629631   0.08782487 -0.47338453  0.35345632 -0.06693023 -0.27646577]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[-0.33073407  0.14612621 -0.06266934 ...  0.84484535 -0.12296543\n",
      "   0.77432895]\n",
      " [-0.8536666  -0.01048076 -0.10002846 ...  0.4412018  -0.23505431\n",
      "   0.6783054 ]\n",
      " [-0.7773089   0.40002573 -0.17473161 ...  0.7971061  -0.21617687\n",
      "   0.8154314 ]\n",
      " ...\n",
      " [-0.53897893  0.20686042  0.33575624 ...  0.5694974  -0.24205497\n",
      "   0.53376555]\n",
      " [-0.5707657   0.10813653  0.18492147 ...  0.8677025  -0.16494572\n",
      "   0.56380117]\n",
      " [-0.56603634  0.1004438   0.17902762 ...  0.80625296 -0.11992311\n",
      "   0.53856736]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866f7a7a-9796-4e93-bbda-dcd4cf8e4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5448bf7c-6049-4c0f-b180-4e7dac6ca4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.508649]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca8b98c-2db1-461e-809d-b2c4cec1cbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6774fad7-2271-4d0c-b276-4b40421b14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56bc55ff-5d5a-4d78-82b8-0e6f662bf27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ca934f-2a7b-4820-a4bf-debceeb055d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf874-f5c9-4131-814d-8cda102906e2",
   "metadata": {},
   "source": [
    "This takes a lot of time (5 hours for imdb data), so skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b64ff96d-30a1-4862-849e-1e6a0d052b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n",
      "Epoch 1/5\n",
      " 60/150 [===========>..................] - ETA: 58:22 - loss: 0.5954 - binary_accuracy: 0.6245"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17749/2243441334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = classifier_model.fit(x=train_ds,\n\u001b[1;32m      3\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8c4e0-b82c-4f1d-84b9-a28f43deb1c6",
   "metadata": {},
   "source": [
    "Results for social distancing data on training data:\n",
    "\n",
    "| type | classes | 1 | 2 | 3 | 4 | 5 |\n",
    "| -- | -- | -- | -- | -- | -- | -- |\n",
    "| bert_en_uncased_L-12_H-768_A-12  | 3 | 0.550 | 0.565 | 0.580 | 0.580 | 0.587 |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 3 | 0.536 | 0.554 | 0.571 | 0.599 | 0.616  |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 2 | 0.791 | 0.797 | 0.843 | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d5fef-e7f3-4ed0-a03a-312a59535c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ffe5e-e957-42a8-9f0c-baf52a6e1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c330f8-4d49-400a-8fca-f308c4e6b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c84ec-fa5b-4ebb-b10b-d3f844fcee1a",
   "metadata": {},
   "source": [
    "Resume processing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf72f10-3858-4e5b-baa8-37e2d8959a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ce021-b9ff-48f1-988b-7eacc93b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'iedereen moet afstand houden',  # this is the same sentence tried earlier\n",
    "    'hou afstand',\n",
    "    'niemand houdt afstand',\n",
    "    'de afstand tot het doel is 11 meter',\n",
    "    'ze moeten stoppen met maatregelen als 1,5 m'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "# original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "# print('Results from the model in memory:')\n",
    "# print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac233bd1-5a70-4394-8087-7e7b33bf8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_results = reloaded_model \\\n",
    "            .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679868d2-0655-4eb1-82e8-607bff08f3fc",
   "metadata": {},
   "source": [
    "### 3.3 Prepare data for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a374f-d02f-4f15-b497-f35f72302f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6eae7-634b-4ec1-bd9e-6b9199e3fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_IN = \"../../puregome/data/annotation/\"\n",
    "TEXT_FILE = os.path.join(DATA_DIR_IN, \"distance-tweets.csv\")\n",
    "LABEL_FILE = TEXT_FILE + \".human-labels.txt\"\n",
    "DATA_DIR_OUT = \"social_distancing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274ada5-9233-45ef-bd3d-6f207e04466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text_df, label_df):\n",
    "    data_dict = {}\n",
    "    target_annotator = \"\"\n",
    "    for i, row in label_df.iterrows():\n",
    "        if target_annotator == \"\":\n",
    "            target_annotator = row[\"annotator\"]\n",
    "        if row[\"id_str\"] in text_df.index and row[\"annotator\"] == target_annotator:\n",
    "            data_dict[row[\"id_str\"]] = { \"label\": row[\"label\"], \"text\": text_df.loc[row[\"id_str\"]][\"text\"] }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabe949-1e4d-4c6b-aa96-c79ead056771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(data_dict):\n",
    "    for id_str in data_dict:\n",
    "        out_dir = os.path.join(DATA_DIR_OUT, data_dict[id_str][\"label\"])\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        out_file = open(os.path.join(out_dir, str(id_str) + \".txt\"), \"w\")\n",
    "        print(data_dict[id_str][\"text\"], file=out_file)\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eab65e-0442-4284-8a77-1c1a7dffc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(TEXT_FILE, index_col=\"id_str\")\n",
    "label_df = pd.read_csv(LABEL_FILE, sep=\" \", header=None, names=[\"annotator\", \"date\", \"id_str\", \"data_set_id\", \"label\"])\n",
    "data_dict = extract_data(text_df, label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48f7c4-1ecc-4016-b839-d3e2ff5436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628f3ad-22f1-47ca-9dfb-9b037ac8fea1",
   "metadata": {},
   "source": [
    "This stores the tweets in subdirectories of `social_distancing` where the names of the subdirectories are equal to the labels and where each tweet is stored in a file named `id_str.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544ba4b-795a-4db0-9ad1-9805a32eeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62e246-6971-402b-b57d-b2b68ef656e2",
   "metadata": {},
   "source": [
    "## 4. ROBBERT\n",
    "\n",
    "Instructions: https://huggingface.co/pdelobelle/robbert-v2-dutch-base and https://github.com/iPieter/RobBERT\n",
    "\n",
    "Requires PyTorch: https://pytorch.org/<br>\n",
    "Installation command (select: pip & CPU): `pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4ae6baa-9f2b-42e3-8066-3ef3c226b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aa0ad21-0f6e-4d17-bacd-83332a81949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Mijn hond is schattig\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0) # Batch size 1\n",
    "outputs = model(**inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a382435-cac1-4a63-86c1-bb8963dd6701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  1840,  1671,    12, 12223,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1fd83ff-69f0-468d-a336-ca26335cd077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2427, 0.1934]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652d85cb-3f72-4cc6-aa2e-8b816a89aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d25db891504c55ae7551600e3a71cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfaf41f93794b3aaec6e3191a052c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26386e4263e64c58aaf8206c395fcd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c1bd526e80424dbba9bc352d6010c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaad43ec41d4526a2ee1cbf0b108822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1d4dce-56f6-449b-87d3-0007909cefc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1636, -0.0760]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d3f7ae-a94a-45cd-b90d-3d70078957fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 495, 405, 16, 364, 225, 1296, 328, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Dit is een test!\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf1c176a-311a-4e2f-b937-e2177d40518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Dit is een test!</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0, 495, 405, 16, 364, 225, 1296, 328, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00b91c11-c08b-4a34-95d6-547287eb584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"The capital of France is <mask>.\", return_tensors=\"pt\")\n",
    "labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd133dc-eb5d-484f-86ed-6219e59b9b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[34.8744, -3.8884, 18.9567,  ...,  2.8639,  5.2812, 11.2557],\n",
       "         [ 8.5224, -2.9420, 19.8858,  ...,  2.7513,  4.0812,  8.5191],\n",
       "         [-3.2755, -4.2489,  9.6843,  ..., -1.3403, -2.0838, -0.4035],\n",
       "         ...,\n",
       "         [-4.8167, -3.8881,  8.3117,  ..., -4.3991, -5.6916,  1.1575],\n",
       "         [20.6686, -4.4710, 20.3602,  ...,  0.9624,  3.1282,  7.1575],\n",
       "         [11.6269, -3.6408, 32.1565,  ...,  2.0802, -0.2959,  9.1577]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727cd5a-9a83-429f-9773-15441a2fb413",
   "metadata": {},
   "source": [
    "## 5. BERT Fine-Tuning Tutorial with PyTorch\n",
    "\n",
    "Python code source: https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38910a5-ef20-45dc-be27-3460f9e3a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 14:38:44.136955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-26 14:38:44.136983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a152cf-f3ee-4727-90cf-58857cb50229",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"social_distancing\"\n",
    "\n",
    "\n",
    "def read_text_file(file_name):\n",
    "    text_file = open(file_name, \"r\")\n",
    "    text = \"\"\n",
    "    for line in text_file.read():\n",
    "        text += line\n",
    "    text_file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_data(data_dir):\n",
    "    data = []\n",
    "    label_values = {'ONEENS': 0, 'EENS': 0, 'ANDERS': 1}\n",
    "    for label in os.listdir(data_dir):\n",
    "        label_dir = os.path.join(DATA_DIR, label)\n",
    "        if label not in label_values:\n",
    "            label_values[label] = len(label_values)\n",
    "        for id_file_name in os.listdir(label_dir):\n",
    "            data.append({\"text\": read_text_file(os.path.join(label_dir, id_file_name)),\n",
    "                         \"label\": label_values[label],\n",
    "                         \"id\": re.sub(\".txt$\", \"\", id_file_name) })\n",
    "    data = sorted(data, key=lambda item: item[\"id\"])\n",
    "    return [data, label_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c938a498-90d9-4569-afad-69ebaa99daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_values = read_data(DATA_DIR)\n",
    "sentences = [ item[\"text\"] for item in data ]\n",
    "file_labels = [ item[\"label\"] for item in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa77ead2-a75e-4416-a709-2deb97b107de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(set(label_values.values()))\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", \n",
    "                                                         num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3035852-f94f-457f-a046-c47c2160fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initial_words(sentence, n):\n",
    "    words = sentence.strip().split()\n",
    "    return \" \".join(words[int(n):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eeb159b-c048-4b69-bc02-82c7f6ff998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_ids(sentences, file_labels, keep_short_only=False):\n",
    "    input_ids, attention_masks, expanded_labels, sentence_sources = [], [], [], []\n",
    "    max_length = 64\n",
    "    for i in range(0, len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        while len(sentence) > 0:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                max_length = max_length,\n",
    "                                truncation=True,\n",
    "                                pad_to_max_length = True,\n",
    "                                add_special_tokens = True,\n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors = 'pt',\n",
    "                           )\n",
    "            if keep_short_only and encoded_dict['attention_mask'][0][max_length-1] != 0:\n",
    "                break\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            expanded_labels.append(file_labels[i])\n",
    "            sentence_sources.append(i)\n",
    "            sentence = remove_initial_words(sentence, int(max_length/2))\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(expanded_labels)\n",
    "    return [input_ids, attention_masks, labels, sentence_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0322382f-6a1b-4cfc-bda6-37cc829f5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_short_sentences(input_ids, sentence_sources):\n",
    "    short_input_ids = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if (i == 0 or sentence_sources[i] != sentence_sources[i-1]) and (i == len(sentence_sources)-1 or sentence_sources[i] != sentence_sources[i+1]):\n",
    "            short_input_ids.append(input_ids[i])\n",
    "    return torch.cat(short_input_ids, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e24f330f-6bcd-4749-990b-12d9abb9c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set sizes: 4781 (train); 598 (validation); 598 (test)\n",
      "3,252 training samples\n",
      "  417 validation samples\n",
      "  872 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "train_end = int(0.8 * len(sentences))\n",
    "validation_end = int(0.9 * len(sentences))\n",
    "\n",
    "input_ids, attention_masks, labels, _ = make_input_ids(sentences[:train_end], file_labels[:train_end], keep_short_only=True)\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "input_ids, attention_masks, labels, _ = make_input_ids(sentences[train_end:validation_end], file_labels[train_end:validation_end], keep_short_only=True)\n",
    "val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "input_ids, attention_masks, labels, sentence_sources = make_input_ids(sentences[validation_end:], file_labels[validation_end:], keep_short_only=False)\n",
    "test_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "print(f\"data set sizes: {train_end} (train); {validation_end - train_end} (validation); {len(sentences) - validation_end} (test)\")\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} test samples'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58d69b1-e497-4269-a080-24a24e411cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac15b1e-3ea5-42d9-a679-2f869a25c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c1dfb1-c75c-428f-a998-c24dfe783710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bfa91a8-7c75-45a9-b68a-038e7736465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9eaa1cf-f5a1-41db-9759-193b32911f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddcf91c3-d678-4cb5-a795-35de84e23f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52c98c8e-27dc-4fd8-9e86-0632d97108df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:01:31    Loss: 0.391.\n",
      "  Batch    20  of    102.    Elapsed: 0:03:04    Loss: 0.438.\n",
      "  Batch    30  of    102.    Elapsed: 0:04:38    Loss: 0.421.\n",
      "  Batch    40  of    102.    Elapsed: 0:06:14    Loss: 0.406.\n",
      "  Batch    50  of    102.    Elapsed: 0:07:49    Loss: 0.400.\n",
      "  Batch    60  of    102.    Elapsed: 0:09:25    Loss: 0.394.\n",
      "  Batch    70  of    102.    Elapsed: 0:10:59    Loss: 0.385.\n",
      "  Batch    80  of    102.    Elapsed: 0:12:33    Loss: 0.380.\n",
      "  Batch    90  of    102.    Elapsed: 0:14:07    Loss: 0.377.\n",
      "  Batch   100  of    102.    Elapsed: 0:15:46    Loss: 0.375.\n",
      "\n",
      "  Average training loss: 0.375\n",
      "  Training epoch took: 0:16:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.734\n",
      "  Validation Loss: 0.564\n",
      "  Validation took: 0:00:45\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:01:57    Loss: 0.447.\n",
      "  Batch    20  of    102.    Elapsed: 0:03:52    Loss: 0.441.\n",
      "  Batch    30  of    102.    Elapsed: 0:05:38    Loss: 0.441.\n",
      "  Batch    40  of    102.    Elapsed: 0:07:19    Loss: 0.430.\n",
      "  Batch    50  of    102.    Elapsed: 0:09:06    Loss: 0.432.\n",
      "  Batch    60  of    102.    Elapsed: 0:10:54    Loss: 0.434.\n",
      "  Batch    70  of    102.    Elapsed: 0:12:33    Loss: 0.436.\n",
      "  Batch    80  of    102.    Elapsed: 0:14:17    Loss: 0.440.\n",
      "  Batch    90  of    102.    Elapsed: 0:15:55    Loss: 0.442.\n",
      "  Batch   100  of    102.    Elapsed: 0:17:36    Loss: 0.444.\n",
      "\n",
      "  Average training loss: 0.447\n",
      "  Training epoch took: 0:17:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.734\n",
      "  Validation Loss: 0.564\n",
      "  Validation took: 0:00:39\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:35:18 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}    Loss: {:.3f}.'.format(step, len(train_dataloader), elapsed, total_train_loss/step))\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].long().to(device)\n",
    "        model.zero_grad()        \n",
    "        model_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            model_output = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65e10b54-a91b-4739-bfc9-cfd8f6b93e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_overview(training_stats):\n",
    "    pd.set_option('precision', 2)\n",
    "    df_stats = pd.DataFrame(data=training_stats)\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1d36241-14a9-40d3-a5a0-9a385f10cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_graph(df_stats):\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xticks()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e489cc4e-a6e1-4589-8748-aecf8b2cd64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0:16:02</td>\n",
       "      <td>0:00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0:17:52</td>\n",
       "      <td>0:00:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.38         0.56           0.73       0:16:02         0:00:45\n",
       "2               0.45         0.56           0.73       0:17:52         0:00:39"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = training_overview(training_stats)\n",
    "training_graph(df_stats)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2c5ea2a-3884-46f4-a1ec-0ce7ab1d2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_dataloader):\n",
    "    print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
    "    model.eval()\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    print('    DONE.')\n",
    "    return [ true_labels, predictions ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b32aea9d-9191-4725-8b80-3ec994368320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_labels(predictions):\n",
    "    prediction_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_labels.extend(np.argmax(predictions[i], axis=1).flatten())\n",
    "    return prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c40616-fb50-4e76-aa7e-440d6c1e6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_evaluation_results(true_labels, predictions):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    print(label_values)\n",
    "    return confusion_matrix(true_labels_flattened, prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c17cddb9-47e5-4e76-a6b6-d93cf908810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_labels(true_labels, predictions, sentence_sources):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    prediction_labels_collapsed = []\n",
    "    true_labels_collapsed = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if i == 0 or sentence_sources[i] != sentence_sources[i-1]:\n",
    "            prediction_labels_collapsed.append(prediction_labels[i])\n",
    "            true_labels_collapsed.append(true_labels_flattened[i])\n",
    "        elif prediction_labels_collapsed[-1] == 0 and prediction_labels[i] == 1:\n",
    "            prediction_labels_collapsed[-1] = prediction_labels[i]\n",
    "    return [ true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4d426ac-ff7e-4a00-9f94-a1e289fa15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 872 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "true_labels, predictions = process_test_data(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1740e1e7-62c1-4ea0-94d6-5def8f98aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_collapsed, predictions_collapsed = collapse_labels(true_labels, predictions, sentence_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a4ae30e-2bc8-4860-82d0-744a694ca555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[410,  36],\n",
       "       [124,  28]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_labels_collapsed, predictions_collapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b442e0fc-5c0f-40c2-a641-ce0c21f2cc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ONEENS': 0, 'EENS': 0, 'ANDERS': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[624,  36],\n",
       "       [183,  29]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_evaluation_results(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ccc7b-9acd-4f7f-8ec3-b791aa090d25",
   "metadata": {},
   "source": [
    "Confusion matrix for three-label task:\n",
    "<pre>\n",
    "{'ONEENS': 0, 'EENS': 1, 'ANDERS': 2}\n",
    "\n",
    "array([[ 50,  41,  22],\n",
    "       [ 13, 106,  16],\n",
    "       [ 10,  56,  23]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953e8a6-c662-49e8-8fa4-9e6f9ff06491",
   "metadata": {},
   "source": [
    "### 5.1 To do\n",
    "\n",
    "1. &#10003; showing validation accuracy during run\n",
    "2. &#10003; testing on all data including tweets of more than mac_length-2 tokens\n",
    "3. perform validation data test like test data test\n",
    "4. 10-cv test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2967235-ceee-4caf-825c-cc38c9c293c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
