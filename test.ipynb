{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b220be2a-9a82-4f7e-8b32-df6296c5f038",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9b504-dfb2-46b2-823c-25b3b7ae4046",
   "metadata": {},
   "source": [
    "## 1. Transformers\n",
    "\n",
    "Testing the usage instructions from https://huggingface.co/transformers/task_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c90588-bcfb-465a-8cbc-42dfcee88a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = classifier(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6649c3-f004-4657-ba4b-6d733bfc5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipe = pipeline(\"ner\")\n",
    "\n",
    "sequence = \"\"\"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO,\n",
    "therefore very close to the Manhattan Bridge which is visible from the window.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8193e18-a121-4f10-a15e-a488356b1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_pipe(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840e14e-c8af-4a31-8377-54481f585ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model(inputs)[0]\n",
    "predictions = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0618ed6-e1b1-4c3c-8a01-ea4063eba729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e396a-b910-4857-80f3-c2e8de553276",
   "metadata": {},
   "source": [
    "## 2. BERT\n",
    "\n",
    "Testing instructions from https://huggingface.co/transformers/model_doc/bert.html\n",
    "\n",
    "There are two groups of BERT modules. The standard one (BERT) uses PyTorch but we need the transformers version (TFBERT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18d4b4-9466-44c4-8d1e-04f5470bb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForTokenClassification.from_pretrained('bert-base-cased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "inputs[\"labels\"] = tf.reshape(tf.constant([1] * tf.size(input_ids).numpy()), (-1, tf.size(input_ids))) # Batch size 1\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c84b1-5258-4cb5-be96-5c5b2b5ded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df626404-0761-4b2d-8941-f272a279251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb7668-2c2a-4395-a07d-d35a490a6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5f407-3daf-40f5-8f47-379a58dbab7d",
   "metadata": {},
   "source": [
    "## 3. BERTje\n",
    "\n",
    "Instructions: https://huggingface.co/GroNLP/bert-base-dutch-cased\n",
    "\n",
    "Alternative models used by Bouma 2021: RobBERT (Delobelle), mBERT (Google), XLM-R (Conneau)\n",
    "\n",
    "BERTje paper also mentions BERT-NL (textdata.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa219b-2274-427b-b53f-f624706b8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26add8ac-f610-46f7-a089-bf2c34faa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"Dit is een test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d76a34-454d-4a26-98e1-c00ac6145ec4",
   "metadata": {},
   "source": [
    "These instructions could be useful: \n",
    "* https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "* https://www.tensorflow.org/official_models/fine_tuning_bert\n",
    "\n",
    "Even more: https://duckduckgo.com/?q=bert+tensorflow+text+classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b68c81-e383-4abb-8adf-9b10bf3d3302",
   "metadata": {},
   "source": [
    "### 3.1 IMDB data set\n",
    "\n",
    "Instructions: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879579d-9af2-4276-8088-b2f9c54f882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daf64f-7eaf-456c-9f07-26c1f3adb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e567d-7a9b-41f3-865e-3d61054ae9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa8b92-2f57-4241-8a03-9c8b8ba35bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c504a-bdd3-4d32-b9ff-d1d263450421",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983aeaf-43c3-4112-8964-578313925629",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd1b5-a102-4cfb-8790-f3a2fc2ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbeaf59-b83a-405c-b154-ff6b283bda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58664363-62e0-4072-a8f2-ef014967f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd5c5f-28a1-45f4-918e-35d4f4234b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beca42-f4b1-4453-9182-f43a18a6329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82479d1a-52ca-4086-ac01-2c36b214fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c310bc-f1f1-415c-993f-94eff5b2f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafad7d-02fd-40e7-b31a-657a876df640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3d33f-9574-4388-8240-31b6995c154b",
   "metadata": {},
   "source": [
    "FATAL ERROR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208a22a-a102-48d3-85ef-53144f00a57b",
   "metadata": {},
   "source": [
    "### 3.2 Sentiment analysis\n",
    "\n",
    "Instructions: https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e139293-9444-4dab-967d-ad9c31e85b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8845cb-31e2-4ff2-92cb-0735c81b9423",
   "metadata": {},
   "source": [
    "Load IMDB data (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e60592-3186-4352-8bfa-503d8ba85abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f51250-79d1-4bca-9590-f3ddc7923992",
   "metadata": {},
   "source": [
    "Load social distancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365461c-88de-4b04-b6fd-4e39c9732367",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "DATA_DIR = 'social_distancing_relevance'\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525a2c4-cffb-45b9-a26f-bc39570283f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(f'Review: {text_batch.numpy()[i]}')\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12399680-406c-4f01-92b2-9a54bbd3a2ad",
   "metadata": {},
   "source": [
    "This is the place where the BERT model is selected. There are mainly English language models available with one multi-lingual model which crashes the machine. No working Dutch models are found at the related website.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af5749-fe8b-4996-a616-97a18484fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'bert_multi_cased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/google/wiki40b-lm-nl/1',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7147730-1d50-45ef-bc74-b322ba74f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9665ef-a704-4c5d-b75d-51a8b9849951",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af5ad4-e759-43b2-b866-e3454d7aab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2732f84-d2e9-4a71-b9d5-6ee745211cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f7a7a-9796-4e93-bbda-dcd4cf8e4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448bf7c-6049-4c0f-b180-4e7dac6ca4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8b98c-2db1-461e-809d-b2c4cec1cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774fad7-2271-4d0c-b276-4b40421b14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc55ff-5d5a-4d78-82b8-0e6f662bf27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca934f-2a7b-4820-a4bf-debceeb055d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf874-f5c9-4131-814d-8cda102906e2",
   "metadata": {},
   "source": [
    "This takes a lot of time (5 hours for imdb data), so skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ff96d-30a1-4862-849e-1e6a0d052b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8c4e0-b82c-4f1d-84b9-a28f43deb1c6",
   "metadata": {},
   "source": [
    "Results for social distancing data on training data:\n",
    "\n",
    "| type | classes | 1 | 2 | 3 | 4 | 5 |\n",
    "| -- | -- | -- | -- | -- | -- | -- |\n",
    "| bert_en_uncased_L-12_H-768_A-12  | 3 | 0.550 | 0.565 | 0.580 | 0.580 | 0.587 |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 3 | 0.536 | 0.554 | 0.571 | 0.599 | 0.616  |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 2 | 0.791 | 0.797 | 0.843 | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d5fef-e7f3-4ed0-a03a-312a59535c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ffe5e-e957-42a8-9f0c-baf52a6e1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c330f8-4d49-400a-8fca-f308c4e6b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c84ec-fa5b-4ebb-b10b-d3f844fcee1a",
   "metadata": {},
   "source": [
    "Resume processing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf72f10-3858-4e5b-baa8-37e2d8959a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ce021-b9ff-48f1-988b-7eacc93b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'iedereen moet afstand houden',  # this is the same sentence tried earlier\n",
    "    'hou afstand',\n",
    "    'niemand houdt afstand',\n",
    "    'de afstand tot het doel is 11 meter',\n",
    "    'ze moeten stoppen met maatregelen als 1,5 m'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "# original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "# print('Results from the model in memory:')\n",
    "# print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac233bd1-5a70-4394-8087-7e7b33bf8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_results = reloaded_model \\\n",
    "            .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679868d2-0655-4eb1-82e8-607bff08f3fc",
   "metadata": {},
   "source": [
    "### 3.3 Prepare data for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a374f-d02f-4f15-b497-f35f72302f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6eae7-634b-4ec1-bd9e-6b9199e3fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_IN = \"../../puregome/data/annotation/\"\n",
    "TEXT_FILE = os.path.join(DATA_DIR_IN, \"distance-tweets.csv\")\n",
    "LABEL_FILE = TEXT_FILE + \".human-labels.txt\"\n",
    "DATA_DIR_OUT = \"social_distancing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274ada5-9233-45ef-bd3d-6f207e04466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text_df, label_df):\n",
    "    data_dict = {}\n",
    "    target_annotator = \"\"\n",
    "    for i, row in label_df.iterrows():\n",
    "        if target_annotator == \"\":\n",
    "            target_annotator = row[\"annotator\"]\n",
    "        if row[\"id_str\"] in text_df.index and row[\"annotator\"] == target_annotator:\n",
    "            data_dict[row[\"id_str\"]] = { \"label\": row[\"label\"], \"text\": text_df.loc[row[\"id_str\"]][\"text\"] }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabe949-1e4d-4c6b-aa96-c79ead056771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(data_dict):\n",
    "    for id_str in data_dict:\n",
    "        out_dir = os.path.join(DATA_DIR_OUT, data_dict[id_str][\"label\"])\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        out_file = open(os.path.join(out_dir, str(id_str) + \".txt\"), \"w\")\n",
    "        print(data_dict[id_str][\"text\"], file=out_file)\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eab65e-0442-4284-8a77-1c1a7dffc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(TEXT_FILE, index_col=\"id_str\")\n",
    "label_df = pd.read_csv(LABEL_FILE, sep=\" \", header=None, names=[\"annotator\", \"date\", \"id_str\", \"data_set_id\", \"label\"])\n",
    "data_dict = extract_data(text_df, label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48f7c4-1ecc-4016-b839-d3e2ff5436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628f3ad-22f1-47ca-9dfb-9b037ac8fea1",
   "metadata": {},
   "source": [
    "This stores the tweets in subdirectories of `social_distancing` where the names of the subdirectories are equal to the labels and where each tweet is stored in a file named `id_str.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544ba4b-795a-4db0-9ad1-9805a32eeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62e246-6971-402b-b57d-b2b68ef656e2",
   "metadata": {},
   "source": [
    "## 4. ROBBERT\n",
    "\n",
    "Instructions: https://huggingface.co/pdelobelle/robbert-v2-dutch-base and https://github.com/iPieter/RobBERT\n",
    "\n",
    "Requires PyTorch: https://pytorch.org/<br>\n",
    "Installation command (select: pip & CPU): `pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae6baa-9f2b-42e3-8066-3ef3c226b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0ad21-0f6e-4d17-bacd-83332a81949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Mijn hond is schattig\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0) # Batch size 1\n",
    "outputs = model(**inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a382435-cac1-4a63-86c1-bb8963dd6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd83ff-69f0-468d-a336-ca26335cd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d85cb-3f72-4cc6-aa2e-8b816a89aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d4dce-56f6-449b-87d3-0007909cefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3f7ae-a94a-45cd-b90d-3d70078957fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"Dit is een test!\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c176a-311a-4e2f-b937-e2177d40518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0, 495, 405, 16, 364, 225, 1296, 328, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b91c11-c08b-4a34-95d6-547287eb584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"The capital of France is <mask>.\", return_tensors=\"pt\")\n",
    "labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd133dc-eb5d-484f-86ed-6219e59b9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727cd5a-9a83-429f-9773-15441a2fb413",
   "metadata": {},
   "source": [
    "## 5. BERT Fine-Tuning Tutorial with PyTorch\n",
    "\n",
    "Python code source: https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38910a5-ef20-45dc-be27-3460f9e3a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a152cf-f3ee-4727-90cf-58857cb50229",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"social_distancing\"\n",
    "LABEL_VALUES = {'ANDERS': 0, 'EENS': 1, 'ONEENS': 2}\n",
    "\n",
    "def read_text_file(file_name):\n",
    "    text_file = open(file_name, \"r\")\n",
    "    text = \"\"\n",
    "    for line in text_file.read():\n",
    "        text += line\n",
    "    text_file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_data(data_dir, label_values):\n",
    "    data = []\n",
    "    for label in os.listdir(data_dir):\n",
    "        label_dir = os.path.join(DATA_DIR, label)\n",
    "        if label not in label_values:\n",
    "            label_values[label] = len(label_values)\n",
    "        for id_file_name in os.listdir(label_dir):\n",
    "            data.append({\"text\": read_text_file(os.path.join(label_dir, id_file_name)),\n",
    "                         \"label\": label_values[label],\n",
    "                         \"id\": re.sub(\".txt$\", \"\", id_file_name) })\n",
    "    data = sorted(data, key=lambda item: item[\"id\"])\n",
    "    return [ data, label_values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938a498-90d9-4569-afad-69ebaa99daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_values = read_data(DATA_DIR, LABEL_VALUES)\n",
    "sentences = [ item[\"text\"] for item in data ]\n",
    "file_labels = [ item[\"label\"] for item in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77ead2-a75e-4416-a709-2deb97b107de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(set(label_values.values()))\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3035852-f94f-457f-a046-c47c2160fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initial_words(sentence, n):\n",
    "    words = sentence.strip().split()\n",
    "    return \" \".join(words[int(n):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb159b-c048-4b69-bc02-82c7f6ff998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_ids(sentences, file_labels, keep_short_only=False):\n",
    "    input_ids, attention_masks, expanded_labels, sentence_sources = [], [], [], []\n",
    "    max_length = 64\n",
    "    for i in range(0, len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        while len(sentence) > 0:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                max_length = max_length,\n",
    "                                truncation=True,\n",
    "                                padding='max_length',\n",
    "                                add_special_tokens = True,\n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors = 'pt',\n",
    "                           )\n",
    "            if keep_short_only and encoded_dict['attention_mask'][0][max_length-1] != 0:\n",
    "                break\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            expanded_labels.append(file_labels[i])\n",
    "            sentence_sources.append(i)\n",
    "            sentence = remove_initial_words(sentence, int(max_length/2))\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(expanded_labels)\n",
    "    return [input_ids, attention_masks, labels, sentence_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322382f-6a1b-4cfc-bda6-37cc829f5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_short_sentences(input_ids, sentence_sources):\n",
    "    short_input_ids = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if (i == 0 or sentence_sources[i] != sentence_sources[i-1]) and (i == len(sentence_sources)-1 or sentence_sources[i] != sentence_sources[i+1]):\n",
    "            short_input_ids.append(input_ids[i])\n",
    "    return torch.cat(short_input_ids, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ad953-82ef-44d5-8373-36007344ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(fold, sentences):\n",
    "    validation_start = int(0.1 * fold * len(sentences))\n",
    "    validation_end = int(0.1 * (fold + 1) * len(sentences))\n",
    "    input_ids, attention_masks, labels, sentence_sources_validation = make_input_ids(sentences[validation_start:validation_end], \n",
    "                                                                                     file_labels[validation_start:validation_end], \n",
    "                                                                                     keep_short_only=False)\n",
    "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    if fold == 0:\n",
    "        training_sentences = []\n",
    "        training_file_labels = []\n",
    "    else:\n",
    "        training_sentences = sentences[:validation_start]\n",
    "        training_file_labels = file_labels[:validation_start]\n",
    "    if fold < 9:\n",
    "        training_sentences.extend(sentences[validation_end:])\n",
    "        training_file_labels.extend(file_labels[validation_end:])\n",
    "    input_ids, attention_masks, labels, _ = make_input_ids(training_sentences, training_file_labels, keep_short_only=True)\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    return [ train_dataset, val_dataset, sentence_sources_validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d69b1-e497-4269-a080-24a24e411cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(fold, sentences):\n",
    "    train_dataset, val_dataset, sentence_sources_validation = make_data(fold, sentences)\n",
    "    print(f\"fold: {fold}; train size: {len(train_dataset)}; validation size: {len(val_dataset)}\")\n",
    "    batch_size = 32\n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset,\n",
    "                sampler = SequentialSampler(val_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr = 2e-5,\n",
    "                      eps = 1e-8\n",
    "                    )\n",
    "    epochs = 2\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "    return [ train_dataset, val_dataset, train_dataloader, validation_dataloader, batch_size, epochs, total_steps, optimizer, scheduler, sentence_sources_validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa91a8-7c75-45a9-b68a-038e7736465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaa1cf-f5a1-41db-9759-193b32911f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32aea9d-9191-4725-8b80-3ec994368320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_labels(predictions):\n",
    "    prediction_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_labels.extend(np.argmax(predictions[i], axis=1).flatten())\n",
    "    return prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cddb9-47e5-4e76-a6b6-d93cf908810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_labels(true_labels, predictions, sentence_sources, label_values):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    prediction_labels_collapsed = []\n",
    "    true_labels_collapsed = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if i == 0 or sentence_sources[i] != sentence_sources[i-1]:\n",
    "            prediction_labels_collapsed.append(prediction_labels[i])\n",
    "            true_labels_collapsed.append(true_labels_flattened[i])\n",
    "        elif prediction_labels[i] != label_values['ANDERS']:\n",
    "            prediction_labels_collapsed[-1] = prediction_labels[i]\n",
    "    return [ true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893ca84-d3ae-4e64-a253-07cb10530377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, device, optimizer, scheduler):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}    Loss: {:.3f}.'.format(step, len(train_dataloader), elapsed, total_train_loss/step))\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].long().to(device)\n",
    "        model.zero_grad()        \n",
    "        model_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    return avg_train_loss, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1658e3-91e3-4b7b-8f2e-b7c9cb00a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, validation_dataloader, device, sentence_sources_validation, label_values):\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    logits_total, label_ids_total = [], []\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            model_output = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        logits_total.append(logits)\n",
    "        label_ids_total.append(label_ids)\n",
    "    true_labels_collapsed, prediction_labels_collapsed = collapse_labels(label_ids_total, logits_total, sentence_sources_validation, label_values)\n",
    "    print(confusion_matrix(true_labels_collapsed, prediction_labels_collapsed))\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    return [ avg_val_accuracy, avg_val_loss, validation_time, true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c98c8e-27dc-4fd8-9e86-0632d97108df",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for fold in range(9, 10):\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = num_labels)\n",
    "    train_dataset, val_dataset, train_dataloader, validation_dataloader, batch_size, epochs, total_steps, optimizer, scheduler, sentence_sources_validation = \\\n",
    "        make_experiment(fold, sentences)\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    if torch.cuda.is_available():\n",
    "         torch.cuda.manual_seed_all(seed_val)\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"======== Fold {fold:2d} ============\")\n",
    "    for epoch_i in range(0, epochs):\n",
    "        avg_train_loss, training_time = train_model(model, train_dataloader, device, optimizer, scheduler)\n",
    "        avg_val_accuracy, avg_val_loss, validation_time, true_labels_collapsed, prediction_labels_collapsed = \\\n",
    "            validate_model(model, validation_dataloader, device, sentence_sources_validation, label_values)\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "    true_labels.extend(true_labels_collapsed)\n",
    "    predicted_labels.extend(prediction_labels_collapsed)\n",
    "    print(\"\")\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d953a10c-d417-40e0-a2f7-4d2196f4f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecf0f7-4dd6-4b5f-ad39-68491020f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(cm):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for i in range(0, len(cm)):\n",
    "        for j in range(0, len(cm)):\n",
    "            if i == j:\n",
    "                correct += cm[i][j]\n",
    "            else:\n",
    "                wrong += cm[i][j]\n",
    "    return correct/(correct+wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a7984-b072-43d4-aa42-e557fc2660fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e10b54-a91b-4739-bfc9-cfd8f6b93e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_overview(training_stats):\n",
    "    pd.set_option('precision', 2)\n",
    "    df_stats = pd.DataFrame(data=training_stats)\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d36241-14a9-40d3-a5a0-9a385f10cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_graph(df_stats):\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xticks()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489cc4e-a6e1-4589-8748-aecf8b2cd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = training_overview(training_stats)\n",
    "training_graph(df_stats)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e195509-f97d-4d27-92b9-c00ff0a39173",
   "metadata": {},
   "source": [
    "### 5.1 Only run when a test set is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5ea2a-3884-46f4-a1ec-0ce7ab1d2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_dataloader):\n",
    "    print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
    "    model.eval()\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    print('    DONE.')\n",
    "    return [ true_labels, predictions ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c40616-fb50-4e76-aa7e-440d6c1e6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_evaluation_results(true_labels, predictions):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    print(label_values)\n",
    "    return confusion_matrix(true_labels_flattened, prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade95ca-1764-4a11-9d5a-cdafe18b9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predictions = process_test_data(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740e1e7-62c1-4ea0-94d6-5def8f98aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_collapsed, predictions_collapsed = collapse_labels(true_labels, predictions, sentence_sources_test, label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ae30e-2bc8-4860-82d0-744a694ca555",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels_collapsed, predictions_collapsed)\n",
    "print(f\"accuracy: {get_accuracy(cm):.3f}\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442e0fc-5c0f-40c2-a641-ce0c21f2cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation_results(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ccc7b-9acd-4f7f-8ec3-b791aa090d25",
   "metadata": {},
   "source": [
    "Confusion matrix for three-label task:\n",
    "<pre>\n",
    "{'ONEENS': 0, 'EENS': 1, 'ANDERS': 2}\n",
    "\n",
    "array([[ 50,  41,  22],\n",
    "       [ 13, 106,  16],\n",
    "       [ 10,  56,  23]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953e8a6-c662-49e8-8fa4-9e6f9ff06491",
   "metadata": {},
   "source": [
    "### 5.2 To do\n",
    "\n",
    "1. &#10003; showing validation accuracy during run\n",
    "2. &#10003; testing on all data including tweets of more than mac_length-2 tokens\n",
    "3. &#10003; perform validation data test like test data test\n",
    "4. &#10003; 10-cv test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3bd660-b4f5-4ca2-8196-99a423034e49",
   "metadata": {},
   "source": [
    "## 6. Evaluate from confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d8b2b-c673-45d4-a48a-46bc63297b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = [\n",
    "       [[ 18, 128,  18], # 0\n",
    "        [  5, 395,  10],\n",
    "        [  1,  20,   2]],\n",
    "       [[ 12,  61,   8], # 1\n",
    "        [ 14, 468,  13],\n",
    "        [  3,  18,   1]],\n",
    "       [[ 18, 102,  10], # 2\n",
    "        [  8, 412,  11],\n",
    "        [  4,  30,   3]],\n",
    "       [[ 20,  88,  24], # 3\n",
    "        [ 19, 342,  20],\n",
    "        [  8,  40,  36]],\n",
    "       [[ 36, 102,  33], # 4\n",
    "        [ 22, 262,  26],\n",
    "        [ 13,  49,  55]],\n",
    "       [[ 26,  87,  23], # 5\n",
    "        [  8, 306,  17],\n",
    "        [  6,  78,  47]],\n",
    "       [[ 17,  85,  19], # 6\n",
    "        [ 13, 252,   9],\n",
    "        [ 14, 116,  72]],\n",
    "       [[ 33,  85,  46], # 7\n",
    "        [ 19, 209,  23],\n",
    "        [ 17,  98,  68]],\n",
    "       [[ 37, 102,  33], # 8\n",
    "        [ 14, 216,  15],\n",
    "        [ 20, 106,  55]],\n",
    "       [[ 20, 111,  21], # 9\n",
    "        [ 10, 198,  25],\n",
    "        [ 23, 113,  77]],\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee452bab-d7aa-4963-aa4a-05f7cfa43255",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_size = len(cms[0])\n",
    "tp, tn, fp, fn = cm_size*[0], cm_size*[0], cm_size*[0], cm_size*[0]\n",
    "correct, wrong = 0, 0\n",
    "largest_class, rest = 0, 0\n",
    "for cm in cms:\n",
    "    for row_i in range(0, cm_size):\n",
    "        for column_i in range(0, cm_size):\n",
    "            if column_i == row_i:\n",
    "                correct += cm[row_i][column_i]\n",
    "                for i in range(0, cm_size):\n",
    "                    if i == row_i:\n",
    "                        tp[i] += cm[row_i][column_i]\n",
    "                    else:\n",
    "                        tn[i] += cm[row_i][column_i]\n",
    "            else:\n",
    "                wrong += cm[row_i][column_i]\n",
    "                for i in range(0, cm_size):\n",
    "                    if i == row_i:\n",
    "                        fn[i] += cm[row_i][column_i]\n",
    "                    elif i == column_i:\n",
    "                        fp[i] += cm[row_i][column_i]\n",
    "                    else:\n",
    "                        tn[i] += cm[row_i][column_i]\n",
    "            if row_i == 1:\n",
    "                largest_class += cm[row_i][column_i]\n",
    "            else:\n",
    "                rest += cm[row_i][column_i]\n",
    "    \n",
    "precision, recall, f1, accuracy = cm_size*[0], cm_size*[0], cm_size*[0], cm_size*[0]\n",
    "for i in range(0, cm_size):\n",
    "    precision[i] = tp[i] / (tp[i] + fp[i])\n",
    "    recall[i] = tp[i] / (tp[i] + fn[i])\n",
    "    f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "    accuracy[i] = (tp[i] + tn[i]) / (tp[i] + tn[i] + fp[i] + fn[i])\n",
    "    print(f\"{i}: precision {precision[i]:0.3f}; recall: {recall[i]:0.3f}; f1: {f1[i]:0.3f}; accuracy: {accuracy[i]:0.3f}\")\n",
    "print(f\"overall accuracy: {correct / (correct+wrong):0.3f}\")\n",
    "print(f\"baseline accuracy: {largest_class / (largest_class+rest):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e81709-6393-47ad-bd1e-729d3446ac47",
   "metadata": {},
   "source": [
    "The overall accuracy should be compared with the score obtained by fastText for this data set: 0.656 (CLIN 31 paper, Table 2). Note that RobBERT only used short tweets (less than 63 tokens, about 68%) for training. The testing data were identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d005e4-bf95-4dfb-be1c-aa6cd4276082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee821c8-e4f9-4b10-ab2c-0c227936984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([sum([sum(row) for row in cm]) for cm in cms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663643ee-a1d6-43d3-beb4-4363c6dd4873",
   "metadata": {},
   "source": [
    "## 7. Token classification\n",
    "\n",
    "Source: \n",
    "* https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb\n",
    "\n",
    "Possible alternatives:\n",
    "* https://www.kaggle.com/akshay235/bert-implementation-on-ner-corpushttps://www.kaggle.com/akshay235/bert-implementation-on-ner-corpus\n",
    "* https://www.kaggle.com/pendu777/bert-for-named-entity-recognitionhttps://www.kaggle.com/pendu777/bert-for-named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa078b-9ee3-4508-a7ac-fd52a82eafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb411d-4b09-460f-82c6-c1831044bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec255710-2dec-41ae-bbf1-5071390baa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ceac9-e539-4ac3-9a11-eef188847e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4c0aa-aa62-473b-89cc-535c95137643",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259233a-6dbe-4f2e-8b5e-d742410ffa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
    "frequencies = data.Tag.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f067a0-82a5-479d-9272-7c6ea0731665",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {}\n",
    "for tag, count in zip(frequencies.index, frequencies):\n",
    "    if tag != \"O\":\n",
    "        if tag[2:5] not in tags.keys():\n",
    "            tags[tag[2:5]] = count\n",
    "        else:\n",
    "            tags[tag[2:5]] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb57a3-d160-4b84-bcee-40dea949c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipped to code blocks related to class removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191459e-88f7-43b1-9fc6-a266832e8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b991e-d904-4569-ba6a-5cd8ce20ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
    "data = data.fillna(method='ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd493f7f-9a72-4dd0-b857-ca8ba4844ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new column called \"sentence\" which groups the words by sentence \n",
    "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
    "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
    "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59759e22-7f4c-481e-b766-9f49fdd58813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ee835-0f04-48fc-b320-59c9bce38315",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e7e27-589c-43c8-9905-754ed5b7762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[41].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303ac50-6a49-43e2-9004-e23bc0d8b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[41].word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6894285-8e1f-4ecb-81c3-dcca771aad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c448a-1bcb-481b-a41f-f26d01237893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index].strip().split()  \n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                                  # is_pretokenized=True, \n",
    "                                  return_offsets_mapping=True, \n",
    "                                  padding='max_length', \n",
    "                                  truncation=True, \n",
    "                                  max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "            if mapping[0] == 0 and mapping[1] != 0:\n",
    "                # overwrite label\n",
    "                encoded_labels[idx] = labels[i]\n",
    "                i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1e6a6-b47a-4f04-be52-11287fbef1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae443c0-6f40-477b-89de-db896a76b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45af5c-85b6-4a38-b66f-ed691b536028",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "    print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea076600-32e8-4e8b-b5f1-47ff63118bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a6a7f-80e2-442c-be07-f70c55093ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4750ef1-e043-457d-ab69-c1d075360455",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb4d98-2057-4191-b97f-80fb4fe80e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d936a-0f6a-4c65-91f9-6fd022625683",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5a8ed-3b3a-4f14-b108-1e79f11d6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f715da0-c85e-4872-912f-668b2c19e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d98f0-1361-4fe6-a1a2-a0303c3090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06451c9f-83ce-4717-acf6-dd6506e03b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edbb90-0375-4462-adff-680ea7216688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d0cd1-8caa-46c1-b5f7-b7715d6bd072",
   "metadata": {},
   "source": [
    "## 8. Example from manual\n",
    "\n",
    "Source: https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11697d7-8718-4fd0-9708-4683869ea287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"John leads Pfizer in India\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088d155-14ec-4382-92a2-5d35eb174423",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace7252-3512-4cd8-988c-b358fd7dc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a614e5-9a56-4abe-9d62-131611d7c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb30ca7-5959-4590-9cd8-fc5e8a0ac79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2list(tensor_data):\n",
    "    return [int(x) for x in list(tensor_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17522a2f-a84f-49b7-b87d-ab2b977799f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token_id in tensor2list(inputs[\"input_ids\"][0]):\n",
    "    print(tokenizer.decode([token_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210dec24-f4ce-442b-a290-6b9b80b6ec1a",
   "metadata": {},
   "source": [
    "See: https://towardsdatascience.com/how-to-use-bert-from-the-hugging-face-transformer-library-d373a22b0209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9df5c-da1c-44cf-91cf-b7161357f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f56107-22c6-4533-bf21-07a65c235b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "softmax = F.softmax(logits, dim = -1)\n",
    "mask_word = softmax[0, mask_index, :]\n",
    "top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n",
    "for token in top_10:\n",
    "    word = tokenizer.decode([token])\n",
    "    new_sentence = text.replace(tokenizer.mask_token, word)\n",
    "    print(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d64b7-6a69-4d86-bb7a-f9cb7c94ef4d",
   "metadata": {},
   "source": [
    "## 9. Roberta Named Entity Recogntion by Erik Novak\n",
    "\n",
    "Source: https://www.kaggle.com/eriknovak/pytorch-roberta-named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84f653e-cb5e-418c-8f15-0907018eac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# pytorch libraries\n",
    "import torch # the main pytorch library\n",
    "import torch.nn as nn # the sub-library containing Softmax, Module and other useful functions\n",
    "import torch.optim as optim # the sub-library containing the common optimizers (SGD, Adam, etc.)\n",
    "\n",
    "# huggingface's transformers library\n",
    "from transformers import RobertaForTokenClassification, RobertaTokenizer\n",
    "\n",
    "# huggingface's datasets library\n",
    "from datasets import load_dataset, Dataset, DatasetDict, Features, Value\n",
    "from datasets.features import Sequence, ClassLabel\n",
    "\n",
    "# the tqdm library used to show the iteration progress\n",
    "import tqdm\n",
    "tqdmn = tqdm.notebook.tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2721e4-962d-45ae-92db-9f23484abca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_version = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(roberta_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ec3796-0b2a-43dd-82b2-8b2e2d4fc0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/home/erikt/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99e6991-85a5-46e0-be9e-3237cd180a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name, ner_tag_ids):\n",
    "    data = { \"id\": [], \"tokens\": [], \"ner_tags\": [] }\n",
    "    tokens = []\n",
    "    ner_tags = []\n",
    "    infile = open(file_name, mode = \"r\", encoding = \"latin1\")\n",
    "    for line in infile:\n",
    "        if not re.search(\"^-DOCSTART-\", line):\n",
    "            try:\n",
    "                token, pos_tag, ner_tag = line.split()\n",
    "                if ner_tag not in ner_tag_ids:\n",
    "                    ner_tag_ids[ner_tag] = len(ner_tag_ids)\n",
    "                tokens.append(token)\n",
    "                ner_tags.append(ner_tag_ids[ner_tag])\n",
    "            except:\n",
    "                if len(tokens) > 0:\n",
    "                    data[\"id\"].append(str(len(data[\"id\"])))\n",
    "                    data[\"tokens\"].append(tokens)\n",
    "                    data[\"ner_tags\"].append(ner_tags)\n",
    "                    ids = []\n",
    "                    tokens = []\n",
    "                    ner_tags = []\n",
    "    if len(ids) > 0:\n",
    "        data[\"id\"].append(ids)\n",
    "        data[\"tokens\"].append(tokens)\n",
    "        data[\"ner_tags\"].append(ner_tags)\n",
    "    infile.close()\n",
    "    return [ data, ner_tag_ids ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5991a280-0a27-4c29-aa92-88a0a724922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_ids = {}\n",
    "dutch_data_train, ner_tag_ids = read_data(\"ner/data/ned.train\", ner_tag_ids)\n",
    "dutch_data_validation, ner_tag_ids = read_data(\"ner/data/ned.testa\", ner_tag_ids)\n",
    "dutch_data_test, ner_tag_ids = read_data(\"ner/data/ned.testb\", ner_tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea78b924-e743-49b5-9644-6715f0cf7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_id = Value('string')\n",
    "features_tokens = Sequence(Value('string'))\n",
    "features_ner_tags = Sequence(ClassLabel(names=list(ner_tag_ids.keys())))\n",
    "features = Features({\"id\": features_id, \"tokens\": features_tokens, \"ner_tags\": features_ner_tags })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf905017-f9ac-4615-862e-3800b36f3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_data_converted = DatasetDict({ \"train\": Dataset.from_dict(dutch_data_train, features=features),\n",
    "                                     \"validation\": Dataset.from_dict(dutch_data_validation, features=features),\n",
    "                                     \"test\": Dataset.from_dict(dutch_data_test, features=features) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7af7d2c-3a0f-4b1c-9872-a170af5d920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = dutch_data_converted[\"train\"].features['ner_tags'].feature.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201d18f0-74d5-4d64-9e74-e6dc4da027bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_encodings(example):\n",
    "    encodings = tokenizer(example['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n",
    "    labels = example['ner_tags'] + [0] * (tokenizer.model_max_length - len(example['ner_tags']))\n",
    "    return { **encodings, 'labels': labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417eae93-2bc2-4edf-9ff6-d3d9bb5c199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6cdaa91f644101809da80da2b16a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15806.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9e0398226543f1bdf54f41db54b145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2895.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87efdc9db1824ae98e3d480f396cb78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dutch_data_converted = dutch_data_converted.map(add_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c24c577-90cf-492d-b23d-09e165388d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_data_converted.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb80fb8-8e2c-4f43-b10d-6430b97feb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dutch_data_converted['train'].features['ner_tags'].feature\n",
    "label2id = { k: labels.str2int(k) for k in labels.names }\n",
    "id2label = { v: k for k, v in label2id.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224b51a7-867f-4acf-82e5-91b9adde6d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForTokenClassification.from_pretrained(roberta_version, num_labels=num_labels)\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b84b2ff-a148-430a-ab00-273a50f77d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db2b64d4-abfa-4223-adf2-ec51643cea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train().to(device)\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7804b5-dd2d-4cef-aabc-4f12c6b09688",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "train_data = torch.utils.data.DataLoader(dutch_data_converted['validation'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3ffcffb-dce4-48a0-8e70-ba26f7b18265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abafb5280acc4788b04d8747b4bf5040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c36957bb4374e078e58c6d04a6c153f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=724.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "for epoch in tqdmn(range(n_epochs)):\n",
    "    current_loss = 0\n",
    "    for i, batch in enumerate(tqdmn(train_data)):\n",
    "        if i >= 100:\n",
    "            break\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        current_loss += loss.item()\n",
    "        if i % 8 == 0 and i > 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(current_loss / 32)\n",
    "            current_loss = 0\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f4ab125-886e-4607-b06c-408e91533803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(train_loss)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel(f'Iterations ({len(train_loss)} examples)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9abca1c8-6ecb-4f67-8f0d-93de3439585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "test_data = torch.utils.data.DataLoader(dutch_data_converted['test'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d80d0f0-7ced-4bd5-9d86-7b3073015b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aacc9d45c041868af196aedafdb6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1299.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f32934f42eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ms_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m         )\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 )\n\u001b[1;32m    429\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         )\n\u001b[1;32m    368\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "confusion = torch.zeros(num_labels, num_labels)\n",
    "found = 0\n",
    "missed = 0\n",
    "wrong = 0\n",
    "\n",
    "for i, batch in enumerate(tqdmn(test_data)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        outputs = model(**batch)\n",
    "            \n",
    "    s_lengths = batch['attention_mask'].sum(dim=1)\n",
    "    for idx, length in enumerate(s_lengths):\n",
    "        true_values = batch['labels'][idx][:length]\n",
    "        pred_values = torch.argmax(outputs[1], dim=2)[idx][:length]\n",
    "        for true, pred in zip(true_values, pred_values):\n",
    "            confusion[true.item()][pred.item()] += 1\n",
    "            if true.item() > 0:\n",
    "                if pred.item() > 0:\n",
    "                    found += 1\n",
    "                else: \n",
    "                    missed += 1\n",
    "            elif pred.item() > 0:\n",
    "                wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e47c5c8-eac6-488e-9880-222257ea5c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.02702702702702703; recall: 0.007142857142857143\n"
     ]
    }
   ],
   "source": [
    "if found + wrong == 0:\n",
    "    precision = 0.0\n",
    "else:\n",
    "    precision = found / (found + wrong)\n",
    "recall = found / (found + missed)\n",
    "\n",
    "print(f\"precision: {precision}; recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d3ddbb2-b31b-4bb7-a345-c9323d9a9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_labels):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0981737d-a3f4-4439-bd8f-dc1eb2cdc409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.matshow(confusion.numpy())\n",
    "\n",
    "labels = list(label2id.keys())\n",
    "ids = np.arange(len(labels))\n",
    "\n",
    "ax.set_ylabel('True Labels', fontsize='x-large')\n",
    "ax.set_xlabel('Pred Labels', fontsize='x-large')\n",
    "\n",
    "ax.set_xticks(ids)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "ax.set_yticks(ids)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccdf7b-4bea-4b20-9582-832113456959",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b39f7335-a00d-4cc9-a15a-26805ae69549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-ORG': 1,\n",
       " 'B-MISC': 2,\n",
       " 'B-PER': 3,\n",
       " 'I-PER': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-MISC': 6,\n",
       " 'I-ORG': 7,\n",
       " 'I-LOC': 8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c377e-c62c-455e-b571-4287cb6e5a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
