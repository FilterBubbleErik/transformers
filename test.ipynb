{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b220be2a-9a82-4f7e-8b32-df6296c5f038",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9b504-dfb2-46b2-823c-25b3b7ae4046",
   "metadata": {},
   "source": [
    "## 1. Transformers\n",
    "\n",
    "Testing the usage instructions from https://huggingface.co/transformers/task_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c90588-bcfb-465a-8cbc-42dfcee88a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = classifier(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6649c3-f004-4657-ba4b-6d733bfc5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipe = pipeline(\"ner\")\n",
    "\n",
    "sequence = \"\"\"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO,\n",
    "therefore very close to the Manhattan Bridge which is visible from the window.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8193e18-a121-4f10-a15e-a488356b1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_pipe(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840e14e-c8af-4a31-8377-54481f585ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model(inputs)[0]\n",
    "predictions = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0618ed6-e1b1-4c3c-8a01-ea4063eba729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e396a-b910-4857-80f3-c2e8de553276",
   "metadata": {},
   "source": [
    "## 2. BERT\n",
    "\n",
    "Testing instructions from https://huggingface.co/transformers/model_doc/bert.html\n",
    "\n",
    "There are two groups of BERT modules. The standard one (BERT) uses PyTorch but we need the transformers version (TFBERT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18d4b4-9466-44c4-8d1e-04f5470bb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForTokenClassification.from_pretrained('bert-base-cased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "inputs[\"labels\"] = tf.reshape(tf.constant([1] * tf.size(input_ids).numpy()), (-1, tf.size(input_ids))) # Batch size 1\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c84b1-5258-4cb5-be96-5c5b2b5ded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df626404-0761-4b2d-8941-f272a279251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb7668-2c2a-4395-a07d-d35a490a6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5f407-3daf-40f5-8f47-379a58dbab7d",
   "metadata": {},
   "source": [
    "## 3. BERTje\n",
    "\n",
    "Instructions: https://huggingface.co/GroNLP/bert-base-dutch-cased\n",
    "\n",
    "Alternative models used by Bouma 2021: RobBERT (Delobelle), mBERT (Google), XLM-R (Conneau)\n",
    "\n",
    "BERTje paper also mentions BERT-NL (textdata.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa219b-2274-427b-b53f-f624706b8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26add8ac-f610-46f7-a089-bf2c34faa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"Dit is een test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d76a34-454d-4a26-98e1-c00ac6145ec4",
   "metadata": {},
   "source": [
    "These instructions could be useful: \n",
    "* https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "* https://www.tensorflow.org/official_models/fine_tuning_bert\n",
    "\n",
    "Even more: https://duckduckgo.com/?q=bert+tensorflow+text+classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b68c81-e383-4abb-8adf-9b10bf3d3302",
   "metadata": {},
   "source": [
    "### 3.1 IMDB data set\n",
    "\n",
    "Instructions: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879579d-9af2-4276-8088-b2f9c54f882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daf64f-7eaf-456c-9f07-26c1f3adb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e567d-7a9b-41f3-865e-3d61054ae9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa8b92-2f57-4241-8a03-9c8b8ba35bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c504a-bdd3-4d32-b9ff-d1d263450421",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983aeaf-43c3-4112-8964-578313925629",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdd1b5-a102-4cfb-8790-f3a2fc2ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbeaf59-b83a-405c-b154-ff6b283bda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58664363-62e0-4072-a8f2-ef014967f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd5c5f-28a1-45f4-918e-35d4f4234b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beca42-f4b1-4453-9182-f43a18a6329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82479d1a-52ca-4086-ac01-2c36b214fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c310bc-f1f1-415c-993f-94eff5b2f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafad7d-02fd-40e7-b31a-657a876df640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3d33f-9574-4388-8240-31b6995c154b",
   "metadata": {},
   "source": [
    "FATAL ERROR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208a22a-a102-48d3-85ef-53144f00a57b",
   "metadata": {},
   "source": [
    "### 3.2 Sentiment analysis\n",
    "\n",
    "Instructions: https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e139293-9444-4dab-967d-ad9c31e85b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8845cb-31e2-4ff2-92cb-0735c81b9423",
   "metadata": {},
   "source": [
    "Load IMDB data (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e60592-3186-4352-8bfa-503d8ba85abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f51250-79d1-4bca-9590-f3ddc7923992",
   "metadata": {},
   "source": [
    "Load social distancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365461c-88de-4b04-b6fd-4e39c9732367",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "DATA_DIR = 'social_distancing_relevance'\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525a2c4-cffb-45b9-a26f-bc39570283f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(f'Review: {text_batch.numpy()[i]}')\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12399680-406c-4f01-92b2-9a54bbd3a2ad",
   "metadata": {},
   "source": [
    "This is the place where the BERT model is selected. There are mainly English language models available with one multi-lingual model which crashes the machine. No working Dutch models are found at the related website.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af5749-fe8b-4996-a616-97a18484fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'bert_multi_cased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/google/wiki40b-lm-nl/1',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'wiki40b-lm-nl':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7147730-1d50-45ef-bc74-b322ba74f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9665ef-a704-4c5d-b75d-51a8b9849951",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af5ad4-e759-43b2-b866-e3454d7aab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2732f84-d2e9-4a71-b9d5-6ee745211cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f7a7a-9796-4e93-bbda-dcd4cf8e4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448bf7c-6049-4c0f-b180-4e7dac6ca4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8b98c-2db1-461e-809d-b2c4cec1cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774fad7-2271-4d0c-b276-4b40421b14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc55ff-5d5a-4d78-82b8-0e6f662bf27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca934f-2a7b-4820-a4bf-debceeb055d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf874-f5c9-4131-814d-8cda102906e2",
   "metadata": {},
   "source": [
    "This takes a lot of time (5 hours for imdb data), so skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ff96d-30a1-4862-849e-1e6a0d052b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8c4e0-b82c-4f1d-84b9-a28f43deb1c6",
   "metadata": {},
   "source": [
    "Results for social distancing data on training data:\n",
    "\n",
    "| type | classes | 1 | 2 | 3 | 4 | 5 |\n",
    "| -- | -- | -- | -- | -- | -- | -- |\n",
    "| bert_en_uncased_L-12_H-768_A-12  | 3 | 0.550 | 0.565 | 0.580 | 0.580 | 0.587 |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 3 | 0.536 | 0.554 | 0.571 | 0.599 | 0.616  |\n",
    "| bert_multi_cased_L-12_H-768_A-12 | 2 | 0.791 | 0.797 | 0.843 | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d5fef-e7f3-4ed0-a03a-312a59535c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ffe5e-e957-42a8-9f0c-baf52a6e1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c330f8-4d49-400a-8fca-f308c4e6b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c84ec-fa5b-4ebb-b10b-d3f844fcee1a",
   "metadata": {},
   "source": [
    "Resume processing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf72f10-3858-4e5b-baa8-37e2d8959a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social_distancing'\n",
    "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ce021-b9ff-48f1-988b-7eacc93b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'iedereen moet afstand houden',  # this is the same sentence tried earlier\n",
    "    'hou afstand',\n",
    "    'niemand houdt afstand',\n",
    "    'de afstand tot het doel is 11 meter',\n",
    "    'ze moeten stoppen met maatregelen als 1,5 m'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "# original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "# print('Results from the model in memory:')\n",
    "# print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac233bd1-5a70-4394-8087-7e7b33bf8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_results = reloaded_model \\\n",
    "            .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679868d2-0655-4eb1-82e8-607bff08f3fc",
   "metadata": {},
   "source": [
    "### 3.3 Prepare data for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a374f-d02f-4f15-b497-f35f72302f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6eae7-634b-4ec1-bd9e-6b9199e3fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_IN = \"../../puregome/data/annotation/\"\n",
    "TEXT_FILE = os.path.join(DATA_DIR_IN, \"distance-tweets.csv\")\n",
    "LABEL_FILE = TEXT_FILE + \".human-labels.txt\"\n",
    "DATA_DIR_OUT = \"social_distancing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274ada5-9233-45ef-bd3d-6f207e04466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text_df, label_df):\n",
    "    data_dict = {}\n",
    "    target_annotator = \"\"\n",
    "    for i, row in label_df.iterrows():\n",
    "        if target_annotator == \"\":\n",
    "            target_annotator = row[\"annotator\"]\n",
    "        if row[\"id_str\"] in text_df.index and row[\"annotator\"] == target_annotator:\n",
    "            data_dict[row[\"id_str\"]] = { \"label\": row[\"label\"], \"text\": text_df.loc[row[\"id_str\"]][\"text\"] }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabe949-1e4d-4c6b-aa96-c79ead056771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(data_dict):\n",
    "    for id_str in data_dict:\n",
    "        out_dir = os.path.join(DATA_DIR_OUT, data_dict[id_str][\"label\"])\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        out_file = open(os.path.join(out_dir, str(id_str) + \".txt\"), \"w\")\n",
    "        print(data_dict[id_str][\"text\"], file=out_file)\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eab65e-0442-4284-8a77-1c1a7dffc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(TEXT_FILE, index_col=\"id_str\")\n",
    "label_df = pd.read_csv(LABEL_FILE, sep=\" \", header=None, names=[\"annotator\", \"date\", \"id_str\", \"data_set_id\", \"label\"])\n",
    "data_dict = extract_data(text_df, label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48f7c4-1ecc-4016-b839-d3e2ff5436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628f3ad-22f1-47ca-9dfb-9b037ac8fea1",
   "metadata": {},
   "source": [
    "This stores the tweets in subdirectories of `social_distancing` where the names of the subdirectories are equal to the labels and where each tweet is stored in a file named `id_str.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544ba4b-795a-4db0-9ad1-9805a32eeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62e246-6971-402b-b57d-b2b68ef656e2",
   "metadata": {},
   "source": [
    "## 4. ROBBERT\n",
    "\n",
    "Instructions: https://huggingface.co/pdelobelle/robbert-v2-dutch-base and https://github.com/iPieter/RobBERT\n",
    "\n",
    "Requires PyTorch: https://pytorch.org/<br>\n",
    "Installation command (select: pip & CPU): `pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae6baa-9f2b-42e3-8066-3ef3c226b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0ad21-0f6e-4d17-bacd-83332a81949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Mijn hond is schattig\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0) # Batch size 1\n",
    "outputs = model(**inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a382435-cac1-4a63-86c1-bb8963dd6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd83ff-69f0-468d-a336-ca26335cd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d85cb-3f72-4cc6-aa2e-8b816a89aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d4dce-56f6-449b-87d3-0007909cefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3f7ae-a94a-45cd-b90d-3d70078957fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"Dit is een test!\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c176a-311a-4e2f-b937-e2177d40518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0, 495, 405, 16, 364, 225, 1296, 328, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b91c11-c08b-4a34-95d6-547287eb584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"The capital of France is <mask>.\", return_tensors=\"pt\")\n",
    "labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd133dc-eb5d-484f-86ed-6219e59b9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727cd5a-9a83-429f-9773-15441a2fb413",
   "metadata": {},
   "source": [
    "## 5. BERT Fine-Tuning Tutorial with PyTorch\n",
    "\n",
    "Python code source: https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38910a5-ef20-45dc-be27-3460f9e3a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 11:59:57.205650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-14 11:59:57.205676: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a152cf-f3ee-4727-90cf-58857cb50229",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"social_distancing\"\n",
    "LABEL_VALUES = {'ANDERS': 0, 'EENS': 1, 'ONEENS': 2}\n",
    "\n",
    "def read_text_file(file_name):\n",
    "    text_file = open(file_name, \"r\")\n",
    "    text = \"\"\n",
    "    for line in text_file.read():\n",
    "        text += line\n",
    "    text_file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_data(data_dir, label_values):\n",
    "    data = []\n",
    "    for label in os.listdir(data_dir):\n",
    "        label_dir = os.path.join(DATA_DIR, label)\n",
    "        if label not in label_values:\n",
    "            label_values[label] = len(label_values)\n",
    "        for id_file_name in os.listdir(label_dir):\n",
    "            data.append({\"text\": read_text_file(os.path.join(label_dir, id_file_name)),\n",
    "                         \"label\": label_values[label],\n",
    "                         \"id\": re.sub(\".txt$\", \"\", id_file_name) })\n",
    "    data = sorted(data, key=lambda item: item[\"id\"])\n",
    "    return [ data, label_values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c938a498-90d9-4569-afad-69ebaa99daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_values = read_data(DATA_DIR, LABEL_VALUES)\n",
    "sentences = [ item[\"text\"] for item in data ]\n",
    "file_labels = [ item[\"label\"] for item in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa77ead2-a75e-4416-a709-2deb97b107de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(set(label_values.values()))\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3035852-f94f-457f-a046-c47c2160fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initial_words(sentence, n):\n",
    "    words = sentence.strip().split()\n",
    "    return \" \".join(words[int(n):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eeb159b-c048-4b69-bc02-82c7f6ff998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_ids(sentences, file_labels, keep_short_only=False):\n",
    "    input_ids, attention_masks, expanded_labels, sentence_sources = [], [], [], []\n",
    "    max_length = 64\n",
    "    for i in range(0, len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        while len(sentence) > 0:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                max_length = max_length,\n",
    "                                truncation=True,\n",
    "                                padding='max_length',\n",
    "                                add_special_tokens = True,\n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors = 'pt',\n",
    "                           )\n",
    "            if keep_short_only and encoded_dict['attention_mask'][0][max_length-1] != 0:\n",
    "                break\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            expanded_labels.append(file_labels[i])\n",
    "            sentence_sources.append(i)\n",
    "            sentence = remove_initial_words(sentence, int(max_length/2))\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(expanded_labels)\n",
    "    return [input_ids, attention_masks, labels, sentence_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0322382f-6a1b-4cfc-bda6-37cc829f5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_short_sentences(input_ids, sentence_sources):\n",
    "    short_input_ids = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if (i == 0 or sentence_sources[i] != sentence_sources[i-1]) and (i == len(sentence_sources)-1 or sentence_sources[i] != sentence_sources[i+1]):\n",
    "            short_input_ids.append(input_ids[i])\n",
    "    return torch.cat(short_input_ids, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872ad953-82ef-44d5-8373-36007344ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(fold, sentences):\n",
    "    validation_start = int(0.1 * fold * len(sentences))\n",
    "    validation_end = int(0.1 * (fold + 1) * len(sentences))\n",
    "    input_ids, attention_masks, labels, sentence_sources_validation = make_input_ids(sentences[validation_start:validation_end], \n",
    "                                                                                     file_labels[validation_start:validation_end], \n",
    "                                                                                     keep_short_only=False)\n",
    "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    if fold == 0:\n",
    "        training_sentences = []\n",
    "        training_file_labels = []\n",
    "    else:\n",
    "        training_sentences = sentences[:validation_start]\n",
    "        training_file_labels = file_labels[:validation_start]\n",
    "    if fold < 9:\n",
    "        training_sentences.extend(sentences[validation_end:])\n",
    "        training_file_labels.extend(file_labels[validation_end:])\n",
    "    input_ids, attention_masks, labels, _ = make_input_ids(training_sentences, training_file_labels, keep_short_only=True)\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    return [ train_dataset, val_dataset, sentence_sources_validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e58d69b1-e497-4269-a080-24a24e411cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(fold, sentences):\n",
    "    train_dataset, val_dataset, sentence_sources_validation = make_data(fold, sentences)\n",
    "    print(f\"fold: {fold}; train size: {len(train_dataset)}; validation size: {len(val_dataset)}\")\n",
    "    batch_size = 32\n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset,\n",
    "                sampler = SequentialSampler(val_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr = 2e-5,\n",
    "                      eps = 1e-8\n",
    "                    )\n",
    "    epochs = 2\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "    return [ train_dataset, val_dataset, train_dataloader, validation_dataloader, batch_size, epochs, total_steps, optimizer, scheduler, sentence_sources_validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bfa91a8-7c75-45a9-b68a-038e7736465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9eaa1cf-f5a1-41db-9759-193b32911f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32aea9d-9191-4725-8b80-3ec994368320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_labels(predictions):\n",
    "    prediction_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_labels.extend(np.argmax(predictions[i], axis=1).flatten())\n",
    "    return prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17cddb9-47e5-4e76-a6b6-d93cf908810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_labels(true_labels, predictions, sentence_sources, label_values):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    prediction_labels_collapsed = []\n",
    "    true_labels_collapsed = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if i == 0 or sentence_sources[i] != sentence_sources[i-1]:\n",
    "            prediction_labels_collapsed.append(prediction_labels[i])\n",
    "            true_labels_collapsed.append(true_labels_flattened[i])\n",
    "        elif prediction_labels[i] != label_values['ANDERS']:\n",
    "            prediction_labels_collapsed[-1] = prediction_labels[i]\n",
    "    return [ true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6893ca84-d3ae-4e64-a253-07cb10530377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, device, optimizer, scheduler):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}    Loss: {:.3f}.'.format(step, len(train_dataloader), elapsed, total_train_loss/step))\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].long().to(device)\n",
    "        model.zero_grad()        \n",
    "        model_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    return avg_train_loss, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1658e3-91e3-4b7b-8f2e-b7c9cb00a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, validation_dataloader, device, sentence_sources_validation, label_values):\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    logits_total, label_ids_total = [], []\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            model_output = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        logits_total.append(logits)\n",
    "        label_ids_total.append(label_ids)\n",
    "    true_labels_collapsed, prediction_labels_collapsed = collapse_labels(label_ids_total, logits_total, sentence_sources_validation, label_values)\n",
    "    print(confusion_matrix(true_labels_collapsed, prediction_labels_collapsed))\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    return [ avg_val_accuracy, avg_val_loss, validation_time, true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c98c8e-27dc-4fd8-9e86-0632d97108df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9; train size: 3669; validation size: 872\n",
      "======== Fold  9 ============\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    10  of    115.    Elapsed: 0:01:30    Loss: 1.008.\n",
      "  Batch    20  of    115.    Elapsed: 0:03:06    Loss: 0.986.\n",
      "  Batch    30  of    115.    Elapsed: 0:04:49    Loss: 0.961.\n",
      "  Batch    40  of    115.    Elapsed: 0:06:22    Loss: 0.954.\n",
      "  Batch    50  of    115.    Elapsed: 0:07:55    Loss: 0.943.\n",
      "  Batch    60  of    115.    Elapsed: 0:09:26    Loss: 0.934.\n",
      "  Batch    70  of    115.    Elapsed: 0:10:58    Loss: 0.924.\n",
      "  Batch    80  of    115.    Elapsed: 0:12:42    Loss: 0.919.\n",
      "  Batch    90  of    115.    Elapsed: 0:14:24    Loss: 0.912.\n",
      "  Batch   100  of    115.    Elapsed: 0:16:12    Loss: 0.905.\n",
      "  Batch   110  of    115.    Elapsed: 0:17:52    Loss: 0.897.\n",
      "\n",
      "  Average training loss: 0.895\n",
      "  Training epoch took: 0:18:40\n",
      "\n",
      "Running Validation...\n",
      "[[ 33 108  11]\n",
      " [ 20 199  14]\n",
      " [ 31 133  49]]\n",
      "  Accuracy: 0.494\n",
      "  Validation Loss: 1.065\n",
      "  Validation took: 0:01:22\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    10  of    115.    Elapsed: 0:01:39    Loss: 0.815.\n",
      "  Batch    20  of    115.    Elapsed: 0:03:41    Loss: 0.795.\n",
      "  Batch    30  of    115.    Elapsed: 0:05:38    Loss: 0.785.\n",
      "  Batch    40  of    115.    Elapsed: 0:07:24    Loss: 0.793.\n",
      "  Batch    50  of    115.    Elapsed: 0:09:04    Loss: 0.786.\n",
      "  Batch    60  of    115.    Elapsed: 0:10:42    Loss: 0.788.\n",
      "  Batch    70  of    115.    Elapsed: 0:12:28    Loss: 0.787.\n",
      "  Batch    80  of    115.    Elapsed: 0:14:18    Loss: 0.781.\n",
      "  Batch    90  of    115.    Elapsed: 0:16:02    Loss: 0.778.\n",
      "  Batch   100  of    115.    Elapsed: 0:17:52    Loss: 0.774.\n",
      "  Batch   110  of    115.    Elapsed: 0:19:41    Loss: 0.771.\n",
      "\n",
      "  Average training loss: 0.771\n",
      "  Training epoch took: 0:20:34\n",
      "\n",
      "Running Validation...\n",
      "[[ 29 102  21]\n",
      " [ 20 189  24]\n",
      " [ 30 105  78]]\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 1.045\n",
      "  Validation took: 0:01:33\n",
      "\n",
      "Total training took 0:42:09 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for fold in range(9, 10):\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = num_labels)\n",
    "    train_dataset, val_dataset, train_dataloader, validation_dataloader, batch_size, epochs, total_steps, optimizer, scheduler, sentence_sources_validation = \\\n",
    "        make_experiment(fold, sentences)\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    if torch.cuda.is_available():\n",
    "         torch.cuda.manual_seed_all(seed_val)\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"======== Fold {fold:2d} ============\")\n",
    "    for epoch_i in range(0, epochs):\n",
    "        avg_train_loss, training_time = train_model(model, train_dataloader, device, optimizer, scheduler)\n",
    "        avg_val_accuracy, avg_val_loss, validation_time, true_labels_collapsed, prediction_labels_collapsed = \\\n",
    "            validate_model(model, validation_dataloader, device, sentence_sources_validation, label_values)\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "    true_labels.extend(true_labels_collapsed)\n",
    "    predicted_labels.extend(prediction_labels_collapsed)\n",
    "    print(\"\")\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d953a10c-d417-40e0-a2f7-4d2196f4f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29, 102,  21],\n",
       "       [ 20, 189,  24],\n",
       "       [ 30, 105,  78]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ecf0f7-4dd6-4b5f-ad39-68491020f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(cm):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for i in range(0, len(cm)):\n",
    "        for j in range(0, len(cm)):\n",
    "            if i == j:\n",
    "                correct += cm[i][j]\n",
    "            else:\n",
    "                wrong += cm[i][j]\n",
    "    return correct/(correct+wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "278a7984-b072-43d4-aa42-e557fc2660fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49498327759197325"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e10b54-a91b-4739-bfc9-cfd8f6b93e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_overview(training_stats):\n",
    "    pd.set_option('precision', 2)\n",
    "    df_stats = pd.DataFrame(data=training_stats)\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1d36241-14a9-40d3-a5a0-9a385f10cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_graph(df_stats):\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xticks()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e489cc4e-a6e1-4589-8748-aecf8b2cd64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0:18:40</td>\n",
       "      <td>0:01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0:20:34</td>\n",
       "      <td>0:01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.90         1.06           0.49       0:18:40         0:01:22\n",
       "2               0.77         1.04           0.52       0:20:34         0:01:33"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = training_overview(training_stats)\n",
    "training_graph(df_stats)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e195509-f97d-4d27-92b9-c00ff0a39173",
   "metadata": {},
   "source": [
    "### 5.1 Only run when a test set is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2c5ea2a-3884-46f4-a1ec-0ce7ab1d2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_dataloader):\n",
    "    print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
    "    model.eval()\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "    print('    DONE.')\n",
    "    return [ true_labels, predictions ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54c40616-fb50-4e76-aa7e-440d6c1e6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_evaluation_results(true_labels, predictions):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    print(label_values)\n",
    "    return confusion_matrix(true_labels_flattened, prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade95ca-1764-4a11-9d5a-cdafe18b9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predictions = process_test_data(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740e1e7-62c1-4ea0-94d6-5def8f98aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_collapsed, predictions_collapsed = collapse_labels(true_labels, predictions, sentence_sources_test, label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ae30e-2bc8-4860-82d0-744a694ca555",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels_collapsed, predictions_collapsed)\n",
    "print(f\"accuracy: {get_accuracy(cm):.3f}\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442e0fc-5c0f-40c2-a641-ce0c21f2cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation_results(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ccc7b-9acd-4f7f-8ec3-b791aa090d25",
   "metadata": {},
   "source": [
    "Confusion matrix for three-label task:\n",
    "<pre>\n",
    "{'ONEENS': 0, 'EENS': 1, 'ANDERS': 2}\n",
    "\n",
    "array([[ 50,  41,  22],\n",
    "       [ 13, 106,  16],\n",
    "       [ 10,  56,  23]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953e8a6-c662-49e8-8fa4-9e6f9ff06491",
   "metadata": {},
   "source": [
    "### 5.2 To do\n",
    "\n",
    "1. &#10003; showing validation accuracy during run\n",
    "2. &#10003; testing on all data including tweets of more than mac_length-2 tokens\n",
    "3. &#10003; perform validation data test like test data test\n",
    "4. &#10003; 10-cv test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3bd660-b4f5-4ca2-8196-99a423034e49",
   "metadata": {},
   "source": [
    "## 6. Evaluate from confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d1d8b2b-c673-45d4-a48a-46bc63297b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = [\n",
    "       [[ 18, 128,  18], # 0\n",
    "        [  5, 395,  10],\n",
    "        [  1,  20,   2]],\n",
    "       [[ 12,  61,   8], # 1\n",
    "        [ 14, 468,  13],\n",
    "        [  3,  18,   1]],\n",
    "       [[ 18, 102,  10], # 2\n",
    "        [  8, 412,  11],\n",
    "        [  4,  30,   3]],\n",
    "       [[ 20,  88,  24], # 3\n",
    "        [ 19, 342,  20],\n",
    "        [  8,  40,  36]],\n",
    "       [[ 36, 102,  33], # 4\n",
    "        [ 22, 262,  26],\n",
    "        [ 13,  49,  55]],\n",
    "       [[ 26,  87,  23], # 5\n",
    "        [  8, 306,  17],\n",
    "        [  6,  78,  47]],\n",
    "       [[ 17,  85,  19], # 6\n",
    "        [ 13, 252,   9],\n",
    "        [ 14, 116,  72]],\n",
    "       [[ 33,  85,  46], # 7\n",
    "        [ 19, 209,  23],\n",
    "        [ 17,  98,  68]],\n",
    "       [[ 37, 102,  33], # 8\n",
    "        [ 14, 216,  15],\n",
    "        [ 20, 106,  55]],\n",
    "       [[ 20, 111,  21], # 9\n",
    "        [ 10, 198,  25],\n",
    "        [ 23, 113,  77]],\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee452bab-d7aa-4963-aa4a-05f7cfa43255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: precision 0.496; recall: 0.167; f1: 0.249; accuracy: 0.761\n",
      "1: precision 0.654; recall: 0.910; f1: 0.761; accuracy: 0.679\n",
      "2: precision 0.507; recall: 0.349; f1: 0.413; accuracy: 0.802\n",
      "overall accuracy: 0.621\n",
      "baseline accuracy: 0.562\n"
     ]
    }
   ],
   "source": [
    "cm_size = len(cms[0])\n",
    "tp, tn, fp, fn = cm_size*[0], cm_size*[0], cm_size*[0], cm_size*[0]\n",
    "correct, wrong = 0, 0\n",
    "largest_class, rest = 0, 0\n",
    "for cm in cms:\n",
    "    for row_i in range(0, cm_size):\n",
    "        for column_i in range(0, cm_size):\n",
    "            if column_i == row_i:\n",
    "                correct += cm[row_i][column_i]\n",
    "                for i in range(0, cm_size):\n",
    "                    if i == row_i:\n",
    "                        tp[i] += cm[row_i][column_i]\n",
    "                    else:\n",
    "                        tn[i] += cm[row_i][column_i]\n",
    "            else:\n",
    "                wrong += cm[row_i][column_i]\n",
    "                for i in range(0, cm_size):\n",
    "                    if i == row_i:\n",
    "                        fn[i] += cm[row_i][column_i]\n",
    "                    elif i == column_i:\n",
    "                        fp[i] += cm[row_i][column_i]\n",
    "                    else:\n",
    "                        tn[i] += cm[row_i][column_i]\n",
    "            if row_i == 1:\n",
    "                largest_class += cm[row_i][column_i]\n",
    "            else:\n",
    "                rest += cm[row_i][column_i]\n",
    "    \n",
    "precision, recall, f1, accuracy = cm_size*[0], cm_size*[0], cm_size*[0], cm_size*[0]\n",
    "for i in range(0, cm_size):\n",
    "    precision[i] = tp[i] / (tp[i] + fp[i])\n",
    "    recall[i] = tp[i] / (tp[i] + fn[i])\n",
    "    f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "    accuracy[i] = (tp[i] + tn[i]) / (tp[i] + tn[i] + fp[i] + fn[i])\n",
    "    print(f\"{i}: precision {precision[i]:0.3f}; recall: {recall[i]:0.3f}; f1: {f1[i]:0.3f}; accuracy: {accuracy[i]:0.3f}\")\n",
    "print(f\"overall accuracy: {correct / (correct+wrong):0.3f}\")\n",
    "print(f\"baseline accuracy: {largest_class / (largest_class+rest):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e81709-6393-47ad-bd1e-729d3446ac47",
   "metadata": {},
   "source": [
    "The overall accuracy should be compared with the score obtained by fastText for this data set: 0.656 (CLIN 31 paper, Table 2). Note that RobBERT only used short tweets (less than 63 tokens, about 68%) for training. The testing data were identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02d005e4-bf95-4dfb-be1c-aa6cd4276082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ee821c8-e4f9-4b10-ab2c-0c227936984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5977"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([sum([sum(row) for row in cm]) for cm in cms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663643ee-a1d6-43d3-beb4-4363c6dd4873",
   "metadata": {},
   "source": [
    "## 7. Token classification\n",
    "\n",
    "Source: \n",
    "* https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb\n",
    "\n",
    "Possible alternatives:\n",
    "* https://www.kaggle.com/akshay235/bert-implementation-on-ner-corpushttps://www.kaggle.com/akshay235/bert-implementation-on-ner-corpus\n",
    "* https://www.kaggle.com/pendu777/bert-for-named-entity-recognitionhttps://www.kaggle.com/pendu777/bert-for-named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fa078b-9ee3-4508-a7ac-fd52a82eafb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/erikt/.local/lib/python3.6/site-packages (3.0.2)\n",
      "Requirement already satisfied: seqeval in /home/erikt/.local/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (0.1.96)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: filelock in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: sacremoses in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: numpy in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: dataclasses in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: packaging in /home/erikt/.local/lib/python3.6/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/erikt/.local/lib/python3.6/site-packages (from seqeval) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/erikt/.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/erikt/.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/erikt/.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/erikt/.local/lib/python3.6/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/erikt/.local/lib/python3.6/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/erikt/.local/lib/python3.6/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/erikt/.local/lib/python3.6/site-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/erikt/.local/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /home/erikt/.local/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /home/erikt/.local/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37cb411d-4b09-460f-82c6-c1831044bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec255710-2dec-41ae-bbf1-5071390baa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5ceac9-e539-4ac3-9a11-eef188847e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a4c0aa-aa62-473b-89cc-535c95137643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #      47959\n",
       "Word          1048575\n",
       "POS           1048575\n",
       "Tag           1048575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0259233a-6dbe-4f2e-8b5e-d742410ffa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
    "frequencies = data.Tag.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f067a0-82a5-479d-9272-7c6ea0731665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"
     ]
    }
   ],
   "source": [
    "tags = {}\n",
    "for tag, count in zip(frequencies.index, frequencies):\n",
    "    if tag != \"O\":\n",
    "        if tag[2:5] not in tags.keys():\n",
    "            tags[tag[2:5]] = count\n",
    "        else:\n",
    "            tags[tag[2:5]] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bb57a3-d160-4b84-bcee-40dea949c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipped to code blocks related to class removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a191459e-88f7-43b1-9fc6-a266832e8ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-per': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-org': 5,\n",
       " 'I-org': 6,\n",
       " 'B-tim': 7,\n",
       " 'B-art': 8,\n",
       " 'I-art': 9,\n",
       " 'I-per': 10,\n",
       " 'I-gpe': 11,\n",
       " 'I-tim': 12,\n",
       " 'B-nat': 13,\n",
       " 'B-eve': 14,\n",
       " 'I-eve': 15,\n",
       " 'I-nat': 16}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e2b991e-d904-4569-ba6a-5cd8ce20ffcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
    "data = data.fillna(method='ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd493f7f-9a72-4dd0-b857-ca8ba4844ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  \\\n",
       "0  Sentence: 1      Thousands  NNS   O   \n",
       "1  Sentence: 1             of   IN   O   \n",
       "2  Sentence: 1  demonstrators  NNS   O   \n",
       "3  Sentence: 1           have  VBP   O   \n",
       "4  Sentence: 1        marched  VBN   O   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Thousands of demonstrators have marched throug...   \n",
       "2  Thousands of demonstrators have marched throug...   \n",
       "3  Thousands of demonstrators have marched throug...   \n",
       "4  Thousands of demonstrators have marched throug...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
       "1  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
       "2  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
       "3  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
       "4  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a new column called \"sentence\" which groups the words by sentence \n",
    "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
    "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
    "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59759e22-7f4c-481e-b766-9f49fdd58813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Families of soldiers killed in the conflict jo...   \n",
       "2  They marched from the Houses of Parliament to ...   \n",
       "3  Police put the number of marchers at 10,000 wh...   \n",
       "4  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
       "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n",
       "2                O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O  \n",
       "3                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97ee835-0f04-48fc-b320-59c9bce38315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47610"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1e7e27-589c-43c8-9905-754ed5b7762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bedfordshire police said Tuesday that Omar Khayam was arrested in Bedford for breaching the conditions of his parole .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[41].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f303ac50-6a49-43e2-9004-e23bc0d8b38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[41].word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6894285-8e1f-4ecb-81c3-dcca771aad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "969c448a-1bcb-481b-a41f-f26d01237893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index].strip().split()  \n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                                  # is_pretokenized=True, \n",
    "                                  return_offsets_mapping=True, \n",
    "                                  padding='max_length', \n",
    "                                  truncation=True, \n",
    "                                  max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "            if mapping[0] == 0 and mapping[1] != 0:\n",
    "                # overwrite label\n",
    "                encoded_labels[idx] = labels[i]\n",
    "                i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2f1e6a6-b47a-4f04-be52-11287fbef1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47610, 2)\n",
      "TRAIN Dataset: (38088, 2)\n",
      "TEST Dataset: (9522, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aae443c0-6f40-477b-89de-db896a76b899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1996,  102,  ...,    0,    0,    0],\n",
       "         [ 101, 4311,  102,  ...,    0,    0,    0],\n",
       "         [ 101, 2360,  102,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2035, 1011,  ...,    0,    0,    0],\n",
       "         [ 101, 3757,  102,  ...,    0,    0,    0],\n",
       "         [ 101, 1012,  102,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'offset_mapping': tensor([[[0, 0],\n",
       "          [0, 3],\n",
       "          [0, 0],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 7],\n",
       "          [0, 0],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 3],\n",
       "          [0, 0],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 3],\n",
       "          [3, 4],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 8],\n",
       "          [0, 0],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 1],\n",
       "          [0, 0],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]]]),\n",
       " 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d45af5c-85b6-4a38-b66f-ed691b536028",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12110/2630519020.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0:10}  {1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36mconvert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_special_tokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "    print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea076600-32e8-4e8b-b5f1-47ff63118bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d37a6a7f-80e2-442c-be07-f70c55093ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4750ef1-e043-457d-ab69-c1d075360455",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12110/1122156590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0minitial_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0minitial_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1721\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m         )\n\u001b[1;32m   1723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aeb4d98-2057-4191-b97f-80fb4fe80e3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12110/1381856387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtr_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411d936a-0f6a-4c65-91f9-6fd022625683",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ba5a8ed-3b3a-4f14-b108-1e79f11d6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f715da0-c85e-4872-912f-668b2c19e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [25, 128] at entry 0 and [35, 128] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12110/3880667032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training epoch: {epoch + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12110/846599134.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [25, 128] at entry 0 and [35, 128] at entry 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f90d98f0-1361-4fe6-a1a2-a0303c3090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06451c9f-83ce-4717-acf6-dd6506e03b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_batch_encode_plus() got an unexpected keyword argument 'is_pretokenized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2879/641238321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2879/719984418.py\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(model, testing_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2879/3008646870.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m                              \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                              \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                              max_length=self.max_len)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# step 3: create token labels only for first word pieces of each tokenized word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2325\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2327\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2328\u001b[0m             )\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2510\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2512\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2513\u001b[0m         )\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _batch_encode_plus() got an unexpected keyword argument 'is_pretokenized'"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4edbb90-0375-4462-adff-680ea7216688",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2879/2291179433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseqeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d0cd1-8caa-46c1-b5f7-b7715d6bd072",
   "metadata": {},
   "source": [
    "## 8. Example from manual\n",
    "\n",
    "Source: https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b11697d7-8718-4fd0-9708-4683869ea287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"John leads Pfizer in India\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e088d155-14ec-4382-92a2-5d35eb174423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=tensor(0.8919, grad_fn=<NllLossBackward>), logits=tensor([[[ 0.0173,  0.2991],\n",
       "         [ 0.1094,  0.2327],\n",
       "         [ 0.0431,  0.0203],\n",
       "         [ 1.2007, -0.5643],\n",
       "         [ 0.6213,  0.2623],\n",
       "         [ 0.8663, -0.1032],\n",
       "         [-0.1352,  0.0848],\n",
       "         [ 0.1742, -0.2151],\n",
       "         [-0.2177,  0.1444]]], grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ace7252-3512-4cd8-988c-b358fd7dc815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2198, 5260, 1052, 8873, 6290, 1999, 2634,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51a614e5-9a56-4abe-9d62-131611d7c0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bb30ca7-5959-4590-9cd8-fc5e8a0ac79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2list(tensor_data):\n",
    "    return [int(x) for x in list(tensor_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17522a2f-a84f-49b7-b87d-ab2b977799f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "john\n",
      "leads\n",
      "p\n",
      "##fi\n",
      "##zer\n",
      "in\n",
      "india\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "for token_id in tensor2list(inputs[\"input_ids\"][0]):\n",
    "    print(tokenizer.decode([token_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210dec24-f4ce-442b-a290-6b9b80b6ec1a",
   "metadata": {},
   "source": [
    "See: https://towardsdatascience.com/how-to-use-bert-from-the-hugging-face-transformer-library-d373a22b0209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37a9df5c-da1c-44cf-91cf-b7161357f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62f56107-22c6-4533-bf21-07a65c235b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12110/2104081917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmask_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "softmax = F.softmax(logits, dim = -1)\n",
    "mask_word = softmax[0, mask_index, :]\n",
    "top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n",
    "for token in top_10:\n",
    "    word = tokenizer.decode([token])\n",
    "    new_sentence = text.replace(tokenizer.mask_token, word)\n",
    "    print(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d64b7-6a69-4d86-bb7a-f9cb7c94ef4d",
   "metadata": {},
   "source": [
    "## 9. Roberta Named Entity Recogntion by Erik Novak\n",
    "\n",
    "Source: https://www.kaggle.com/eriknovak/pytorch-roberta-named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c84f653e-cb5e-418c-8f15-0907018eac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# pytorch libraries\n",
    "import torch # the main pytorch library\n",
    "import torch.nn as nn # the sub-library containing Softmax, Module and other useful functions\n",
    "import torch.optim as optim # the sub-library containing the common optimizers (SGD, Adam, etc.)\n",
    "\n",
    "# huggingface's transformers library\n",
    "from transformers import RobertaForTokenClassification, RobertaTokenizer\n",
    "\n",
    "# huggingface's datasets library\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from datasets.features import Sequence, ClassLabel\n",
    "\n",
    "# the tqdm library used to show the iteration progress\n",
    "import tqdm\n",
    "tqdmn = tqdm.notebook.tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2721e4-962d-45ae-92db-9f23484abca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_version = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(roberta_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c9ec3796-0b2a-43dd-82b2-8b2e2d4fc0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/home/erikt/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "de5f812c-3779-420f-9a62-908f917ef217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b99e6991-85a5-46e0-be9e-3237cd180a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    data = { \"id\": [], \"tokens\": [], \"ner_tags\": [] }\n",
    "    tokens = []\n",
    "    ner_tags = []\n",
    "    infile = open(file_name, mode = \"r\", encoding = \"latin1\")\n",
    "    for line in infile:\n",
    "        if not re.search(\"^-DOCSTART-\", line):\n",
    "            try:\n",
    "                token, pos_tag, ner_tag = line.split()\n",
    "                tokens.append(token)\n",
    "                ner_tags.append(ner_tag)\n",
    "            except:\n",
    "                if len(tokens) > 0:\n",
    "                    data[\"id\"].append(str(len(data[\"id\"])))\n",
    "                    data[\"tokens\"].append(tokens)\n",
    "                    data[\"ner_tags\"].append(ner_tags)\n",
    "                    ids = []\n",
    "                    tokens = []\n",
    "                    ner_tags = []\n",
    "    if len(ids) > 0:\n",
    "        data[\"id\"].append(ids)\n",
    "        data[\"tokens\"].append(tokens)\n",
    "        data[\"ner_tags\"].append(ner_tags)\n",
    "    infile.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5991a280-0a27-4c29-aa92-88a0a724922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_data_train = read_data(\"ner/data/ned.train\")\n",
    "dutch_data_validation = read_data(\"ner/data/ned.testa\")\n",
    "dutch_data_test = read_data(\"ner/data/ned.testb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8d4f60d3-674d-41a1-8908-789d98975fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_values = list(set([item for sublist in dutch_data_train[\"ner_tags\"] for item in sublist ]))\n",
    "dutch_data = DatasetDict({ \"train\": Dataset.from_dict(dutch_data_train),\n",
    "                           \"validation\": Dataset.from_dict(dutch_data_validation),\n",
    "                           \"test\": Dataset.from_dict(dutch_data_test) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2cbf370c-62c4-49b0-abb2-8854682be9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_data[\"train\"].features[\"ner_tags\"] = Sequence(feature=ClassLabel(num_classes=len(feature_values), names=feature_values, names_file=None, id=None), length=-1, id=None)\n",
    "dutch_data[\"validation\"].features[\"ner_tags\"] = dutch_data[\"train\"].features[\"ner_tags\"]\n",
    "dutch_data[\"test\"].features[\"ner_tags\"] = dutch_data[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "12630114-64ba-488c-9ddc-2548b03c7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = dutch_data[\"train\"].features['ner_tags'].feature.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "86ad98cc-3419-4336-a8c5-359aad08391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_encodings(example):\n",
    "    \"\"\"Processing the example\n",
    "    \n",
    "    Args:\n",
    "        example (dict): The dataset example.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The dictionary containing the following updates:\n",
    "            - input_ids: The list of input ids of the tokens.\n",
    "            - attention_mask: The attention mask list.\n",
    "            - ner_tags: The updated ner_tags.\n",
    "    \n",
    "    \"\"\"\n",
    "    # get the encodings of the tokens. The tokens are already split, that is why we must add is_split_into_words=True\n",
    "    encodings = tokenizer(example['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n",
    "    # extend the ner_tags so that it matches the max_length of the input_ids\n",
    "    labels = example['ner_tags'] + [0] * (tokenizer.model_max_length - len(example['ner_tags']))\n",
    "    # return the encodings and the extended ner_tags\n",
    "    return { **encodings, 'labels': labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "400bada7-3c84-4e9a-97c9-bc8d331f8910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b6d3cb92cd4dd6ada8f8c76de312c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15806.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "Expected bytes, got a 'int' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                                 \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m                                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, example, writer_batch_size)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwriter_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_examples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_examples_on_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mwrite_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m             )\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mpa_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyped_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0minferred_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36m__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrying_type\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: Expected bytes, got a 'int' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-c976a1e80125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdutch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdutch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             }\n\u001b[1;32m    469\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             }\n\u001b[1;32m    469\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                 \u001b[0mdisable_nullable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_nullable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                 \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m             )\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m         }\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   1841\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m                         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1844\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtmp_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m                         \u001b[0mtmp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self, close_stream)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_stream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_rows_on_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_examples_on_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpa_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36mwrite_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_examples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_try_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             )\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mpa_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyped_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0minferred_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mfirst_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizedTypedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyped_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36m__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtensionArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrying_type\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 raise TypeError(\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: Expected bytes, got a 'int' object"
     ]
    }
   ],
   "source": [
    "dutch_data = dutch_data.map(add_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea2a0ff-b6b7-41df-bc2a-c1248c792573",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ffe3167-80f5-4419-b839-d2abecc3a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['train'].features['ner_tags'].feature\n",
    "label2id = { k: labels.str2int(k) for k in labels.names }\n",
    "id2label = { v: k for k, v in label2id.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f786171-248b-483e-a563-f95db4ed7fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForTokenClassification.from_pretrained(roberta_version, num_labels=num_labels)\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed74395-493b-481d-8873-81f8314b1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34bfa7a-a981-405f-b2d9-afcb5a82e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train().to(device)\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50545541-3e4f-43b5-bcf9-cd75575bba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "train_data = torch.utils.data.DataLoader(dataset['train'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b55f3acf-77d1-4cc5-b137-ccdfd95f0192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d4886267184d59b4946bbb4661cdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b913cfcfa540e98ed42e9a8fddd865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cc02ae0e254ebdb54b3a594af9a7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae46f979dbe42c08cd70bacf8228770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "# iterate through the data 'n_epochs' times\n",
    "for epoch in tqdmn(range(n_epochs)):\n",
    "    current_loss = 0\n",
    "    # iterate through each batch of the train data\n",
    "    for i, batch in enumerate(tqdmn(train_data)):\n",
    "        if i >= 4:\n",
    "            break\n",
    "        # move the batch tensors to the same device as the \n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        # send 'input_ids', 'attention_mask' and 'labels' to the model\n",
    "        outputs = model(**batch)\n",
    "        # the outputs are of shape (loss, logits)\n",
    "        loss = outputs[0]\n",
    "        # with the .backward method it calculates all \n",
    "        # of  the gradients used for autograd\n",
    "        loss.backward()\n",
    "        # NOTE: if we append `loss` (a tensor) we will force the GPU to save\n",
    "        # the loss into its memory, potentially filling it up. To avoid this\n",
    "        # we rather store its float value, which can be accessed through the\n",
    "        # `.item` method\n",
    "        current_loss += loss.item()\n",
    "        if i % 8 == 0 and i > 0:\n",
    "            # update the model using the optimizer\n",
    "            optimizer.step()\n",
    "            # once we update the model we set the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # store the loss value for visualization\n",
    "            train_loss.append(current_loss / 32)\n",
    "            current_loss = 0\n",
    "    # update the model one last time for this epoch\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1c101ee-6d1d-469c-80fb-a772ee292c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "# visualize the loss values\n",
    "ax.plot(train_loss)\n",
    "# set the labels\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Iterations (32 examples)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14b1daff-4b6c-4617-855e-e3bc53dec078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "# batch the train data so that each batch contains 4 examples (using 'batch_size')\n",
    "test_data = torch.utils.data.DataLoader(dataset['test'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5efa71b6-f774-435c-8344-7a028f3f949b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cfd49319e545b4a2ad8f05d3ecaff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=864.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create the confusion matrix\n",
    "confusion = torch.zeros(num_labels, num_labels)\n",
    "\n",
    "# iterate through each batch of the train data\n",
    "for i, batch in enumerate(tqdmn(test_data)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    # do not calculate the gradients\n",
    "    with torch.no_grad():\n",
    "        # move the batch tensors to the same device as the model\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        # send 'input_ids', 'attention_mask' and 'labels' to the model\n",
    "        outputs = model(**batch)\n",
    "            \n",
    "    # get the sentence lengths\n",
    "    s_lengths = batch['attention_mask'].sum(dim=1)\n",
    "    # iterate through the examples\n",
    "    for idx, length in enumerate(s_lengths):\n",
    "        # get the true values\n",
    "        true_values = batch['labels'][idx][:length]\n",
    "        # get the predicted values\n",
    "        pred_values = torch.argmax(outputs[1], dim=2)[idx][:length]\n",
    "        # go through all true and predicted values and store them in the confusion matrix\n",
    "        for true, pred in zip(true_values, pred_values):\n",
    "            confusion[true.item()][pred.item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3480247c-9a62-426d-a664-3bab403a77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by dividing every row by its sum\n",
    "for i in range(num_labels):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba96c7e6-41b6-4655-96d6-99cb5620873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# visualize the loss values\n",
    "ax.matshow(confusion.numpy())\n",
    "\n",
    "# get the labels\n",
    "labels = list(label2id.keys())\n",
    "ids = np.arange(len(labels))\n",
    "\n",
    "ax.set_ylabel('True Labels', fontsize='x-large')\n",
    "ax.set_xlabel('Pred Labels', fontsize='x-large')\n",
    "\n",
    "# set the x ticks\n",
    "ax.set_xticks(ids)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# set the y ticks\n",
    "ax.set_yticks(ids)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "# plot figure\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b289f3d-a817-4d3d-8503-5dbd33006d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
